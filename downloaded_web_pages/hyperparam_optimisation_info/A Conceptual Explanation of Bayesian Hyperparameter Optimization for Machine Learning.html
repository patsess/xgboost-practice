<!DOCTYPE html>
<!-- saved from url=(0141)https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f -->
<html xmlns:cc="http://creativecommons.org/ns#"><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# medium-com: http://ogp.me/ns/fb/medium-com#"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=contain"><title>A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning</title><link rel="canonical" href="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f"><meta name="title" content="A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning"><meta name="referrer" content="always"><meta name="description" content="Following are four common methods of hyperparameter optimization for machine learning in order of increasing efficiency: I was pretty proud that I’d recently moved up the ladder from manual to random…"><meta name="theme-color" content="#000000"><meta property="og:title" content="A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning"><meta property="twitter:title" content="A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning"><meta property="og:url" content="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1200/1*CtJD4zJr6PNxbUZMwZxPKA.jpeg"><meta property="fb:app_id" content="542599432471018"><meta property="og:description" content="The concepts behind efficient hyperparameter tuning using Bayesian optimization"><meta name="twitter:description" content="The concepts behind efficient hyperparameter tuning using Bayesian optimization"><meta name="twitter:image:src" content="https://cdn-images-1.medium.com/max/1200/1*CtJD4zJr6PNxbUZMwZxPKA.jpeg"><link rel="publisher" href="https://plus.google.com/103654360130207659246"><link rel="author" href="https://towardsdatascience.com/@williamkoehrsen"><meta property="author" content="Will Koehrsen"><meta property="og:type" content="article"><meta name="twitter:card" content="summary_large_image"><meta property="article:publisher" content="https://www.facebook.com/towardsdatascience"><meta property="article:author" content="Will Koehrsen"><meta name="robots" content="index, follow"><meta property="article:published_time" content="2018-06-24T13:25:59.216Z"><meta name="twitter:creator" content="@koehrsen_will"><meta name="twitter:site" content="@TDataScience"><meta property="og:site_name" content="Towards Data Science"><meta name="twitter:label1" value="Reading time"><meta name="twitter:data1" value="14 min read"><meta name="twitter:app:name:iphone" content="Medium"><meta name="twitter:app:id:iphone" content="828256236"><meta name="twitter:app:url:iphone" content="medium://p/b8172278050f"><meta property="al:ios:app_name" content="Medium"><meta property="al:ios:app_store_id" content="828256236"><meta property="al:android:package" content="com.medium.reader"><meta property="al:android:app_name" content="Medium"><meta property="al:ios:url" content="medium://p/b8172278050f"><meta property="al:android:url" content="medium://p/b8172278050f"><meta property="al:web:url" content="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f"><link rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://towardsdatascience.com/osd.xml"><link rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/b8172278050f"><script async="" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/branch-latest.min.js"></script><script type="application/ld+json">{"@context":"http://schema.org","@type":"NewsArticle","image":{"@type":"ImageObject","width":1920,"height":1080,"url":"https://cdn-images-1.medium.com/max/1920/1*CtJD4zJr6PNxbUZMwZxPKA.jpeg"},"url":"https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f","dateCreated":"2018-06-24T13:25:59.216Z","datePublished":"2018-06-24T13:25:59.216Z","dateModified":"2018-07-02T20:53:28.248Z","headline":"A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning","name":"A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning","thumbnailUrl":"https://cdn-images-1.medium.com/max/1920/1*CtJD4zJr6PNxbUZMwZxPKA.jpeg","keywords":["Tag:Machine Learning","Tag:Education","Tag:Bayesian Machine Learning","Tag:Computer Science","Tag:Towards Data Science","Topic:Artificial Intelligence","Topic:Data Science","Publication:towards-data-science","LockedPostSource:0","Elevated:false","LayerCake:3"],"author":{"@type":"Person","name":"Will Koehrsen","url":"https://towardsdatascience.com/@williamkoehrsen"},"creator":["Will Koehrsen"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"https://towardsdatascience.com","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https://cdn-images-1.medium.com/max/308/1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f"}</script><meta name="parsely-link" content="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f"><link rel="stylesheet" type="text/css" class="js-glyph-" id="glyph-8" href="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/m2.css"><link rel="stylesheet" href="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/main-branding-base.kEJRoqZO5F1dw3WjktWEuw.css"><script>if (window.top !== window.self) window.top.location = window.self.location.href;var OB_startTime = new Date().getTime(); var OB_loadErrors = []; function _onerror(e) { OB_loadErrors.push(e) }; if (document.addEventListener) document.addEventListener("error", _onerror, true); else if (document.attachEvent) document.attachEvent("onerror", _onerror); function _asyncScript(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("script"); s.type = "text/javascript"; s.async = true; s.src = u; f.parentNode.insertBefore(s, f);}function _asyncStyles(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("link"); s.rel = "stylesheet"; s.href = u; f.parentNode.insertBefore(s, f); return s}(new Image()).src = "/_/stat?event=pixel.load&origin=" + encodeURIComponent(location.origin);</script><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga("create", "UA-24232453-2", "auto", {"allowLinker": true, "legacyCookieDomain": window.location.hostname}); ga("send", "pageview");ga("create", "UA-19707169-24", "auto", 'tracker0'); ga("tracker0.send", "pageview");</script><script async="" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/analytics.js"></script><!--[if lt IE 9]><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js"></script><![endif]--><link rel="icon" href="https://cdn-images-1.medium.com/fit/c/128/128/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg" class="js-favicon"><link rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/152/152/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/120/120/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/76/76/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="apple-touch-icon" sizes="60x60" href="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"></head><body itemscope="" class="postShowScreen browser-chrome is-withMagicUnderlinesv-glyph v-glyph--m2 is-js is-withMagicUnderlines is-resizing" data-action-scope="_actionscope_0"><script>document.body.className = document.body.className.replace(/(^|\s)is-noJs(\s|$)/, "$1is-js$2")</script><div class="site-main surface-container" id="container"><div class="butterBar butterBar--error" data-action-scope="_actionscope_1"></div><div class="surface" id="_obv.shell._surface_1545690148786" style="display: block; visibility: visible;"><div class="screenContent surface-content is-supplementalPostContentLoaded" data-used="true" data-action-scope="_actionscope_2"><canvas class="canvas-renderer" width="1284" height="669"></canvas><div class="container u-maxWidth740 u-xs-margin0 notesPositionContainer js-notesPositionContainer"><div class="notesMarkers" data-action-scope="_actionscope_4"><div class="paragraphControls js-paragraphControl js-paragraphControl-9a9e u-noUserSelect is-visible" style="top: 2348px;"><span class="paragraphControls-itemText"><button class="button button--chromeless" data-action="select-anchor" data-action-value="9a9e">Top highlight</button></span></div></div></div><div class="metabar u-clearfix js-metabar u-textColorTransparentWhiteDarker u-fixed u-backgroundTransparentWhiteDarkest u-xs-sizeFullViewportWidth u-tintBgColor u-tintSpectrum"><div class="branch-journeys-top"></div><div class="js-metabarMiddle metabar-inner u-marginAuto u-maxWidth1032 u-flexCenter u-justifyContentSpaceBetween u-height65 u-xs-height56 u-paddingHorizontal20"><div class="metabar-block u-flex1 u-flexCenter"><div class="u-xs-hide js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-fillTransparentBlackDarker u-flex0 u-flexCenter u-paddingTop0"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0"><svg class="svgIcon-use" width="45" height="45"><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div><div class="u-xs-show js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-fillTransparentBlackDarker u-flex0 u-flexCenter u-paddingTop0"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-flex0 u-flexCenter u-paddingTop0"><svg class="svgIcon-use" width="45" height="45"><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div><div class="u-flexCenter u-height65 u-xs-height56"><span class="u-inlineBlock u-height28 u-xs-height24 u-verticalAlignTop u-marginRight20 u-marginLeft15 u-borderRightTransparentWhiteLighter"></span></div><div class="u-flexCenter u-height65 u-xs-height56 u-marginRight18"><a class="js-collectionLogoOrName u-uiTextBold u-fontSize18 u-lineHeightTightest u-xs-fontSize22" href="https://towardsdatascience.com/?source=logo-lo_UCXUIzDzRwYd---7f60cf5620c9"><span class="u-xs-noWrapWithEllipsis u-xs-maxWidth200">Towards Data Science</span></a></div><div class="u-flexCenter u-height65 u-xs-height56 u-xs-hide"><div class="buttonSet"><button class="button button--primary button--smallest u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton is-smallPill" data-action="sign-up-prompt" data-sign-in-action="toggle-follow-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/towards-data-science" data-action-source="----7f60cf5620c9----------------------follow_header" data-collection-id="7f60cf5620c9"><span class="button-label  js-buttonLabel">Follow</span></button></div></div></div><div class="metabar-block u-flex0 u-flexCenter"><div class="u-flexCenter u-height65 u-xs-height56"><div class="buttonSet buttonSet--wide u-lineHeightInherit"><a class="button button--primary button--light button--chromeless u-accentColor--buttonNormal is-inSiteNavBar u-xs-hide js-signInButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f&amp;source=--------------------------nav_reg&amp;operation=login" data-action="sign-in-prompt" data-redirect="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f" data-action-source="--------------------------nav_reg">Sign in</a><a class="button button--primary button--light button--withChrome u-accentColor--buttonNormal is-inSiteNavBar js-signUpButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f&amp;source=--------------------------nav_reg&amp;operation=register" data-action="sign-up-prompt" data-redirect="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f" data-action-source="--------------------------nav_reg">Get started</a></div></div></div></div><div class="metabar-inner u-marginAuto u-maxWidth1032 js-metabarBottom"><nav role="navigation" class="metabar-block metabar-block--below u-overflowHidden u-height44"><ul class="u-textAlignLeft u-noWrap u-overflowX u-paddingBottom100 u-sm-paddingLeft20 u-sm-paddingRight20 js-collectionNavItems"><li class="metabar-navItem js-collectionNavItem u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken u-baseColor--link js-homeNav" href="https://towardsdatascience.com/">Home</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/data-science/home">Data Science</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/machine-learning/home">Machine Learning</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/programming/home">Programming</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/data-visualization/home">Visualization</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/artificial-intelligence/home">AI</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/editors-picks/home">Picks</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/contribute/home">Contribute</a></li><li class="metabar-navItem js-collectionNavItem u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-top1" href="https://towardsdatascience.com/search" title="Search" aria-label="Search"><span class="button-defaultState"><span class="svgIcon svgIcon--search svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M20.067 18.933l-4.157-4.157a6 6 0 1 0-.884.884l4.157 4.157a.624.624 0 1 0 .884-.884zM6.5 11c0-2.62 2.13-4.75 4.75-4.75S16 8.38 16 11s-2.13 4.75-4.75 4.75S6.5 13.62 6.5 11z"></path></svg></span></span></a></li></ul></nav></div></div><div class="metabar metabar--spacer js-metabarSpacer u-tintBgColor  u-height105 u-xs-height95"></div><main role="main"><article class=" u-minHeight100vhOffset65 u-overflowHidden postArticle postArticle--full is-withAccentColors u-marginBottom40" lang="en"><header class="container u-maxWidth740"></header><div class="postArticle-content js-postField js-notesSource js-trackedPost" data-post-id="b8172278050f" data-source="post_page" data-collection-id="7f60cf5620c9" data-tracking-context="postPage" data-scroll="native"><section name="f037" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--outsetColumn"><figure name="d29d" id="d29d" class="graf graf--figure graf--layoutOutsetCenter graf--leading" data-scroll="native"><div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 563px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.3%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*CtJD4zJr6PNxbUZMwZxPKA.jpeg" data-width="1920" data-height="1080" data-action="zoom" data-action-value="1*CtJD4zJr6PNxbUZMwZxPKA.jpeg" data-scroll="native"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_CtJD4zJr6PNxbUZMwZxPKA.jpeg" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="40"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*CtJD4zJr6PNxbUZMwZxPKA.jpeg" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_CtJD4zJr6PNxbUZMwZxPKA(1).jpeg"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*CtJD4zJr6PNxbUZMwZxPKA.jpeg"></noscript></div></div></figure></div><div class="section-inner sectionLayout--insetColumn"><h1 name="656a" id="656a" class="graf graf--h3 graf-after--figure graf--title">A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine&nbsp;Learning</h1><h2 name="b640" id="b640" class="graf graf--h4 graf-after--h3 graf--subtitle">The concepts behind efficient hyperparameter tuning using Bayesian optimization</h2><div class="uiScale uiScale-ui--regular uiScale-caption--regular u-flexCenter u-marginVertical24 u-fontSize15 js-postMetaLockup"><div class="u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@williamkoehrsen?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="e2f299e30cb9" data-action-type="hover" data-user-id="e2f299e30cb9" data-collection-slug="towards-data-science" dir="auto"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_SckxdIFfjlR-cWXkL5ya-g.jpeg" class="avatar-image u-size50x50" alt="Go to the profile of Will Koehrsen"></a></div><div class="u-flex1 u-paddingLeft15 u-overflowHidden"><div class="u-lineHeightTightest u-paddingBottom3"><a class="ds-link ds-link--styleSubtle ui-captionStrong u-inlineBlock link link--darken link--darker" href="https://towardsdatascience.com/@williamkoehrsen?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="e2f299e30cb9" data-action-type="hover" data-user-id="e2f299e30cb9" data-collection-slug="towards-data-science" dir="auto">Will Koehrsen</a><span class="followState js-followState" data-user-id="e2f299e30cb9"><button class="button button--smallest u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f" data-action-source="post_header_lockup"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--smallest button--dark u-noUserSelect button--withChrome u-accentColor--buttonDark button--follow js-followButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/e2f299e30cb9" data-action-source="post_header_lockup-e2f299e30cb9-------------------------follow_byline"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="ui-caption postMetaInline u-fontSize13 u-lineHeightBase js-testPostMetaInlineSupplemental"><time datetime="2018-06-24T13:25:59.216Z">Jun 24</time><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="14 min read"></span></div></div></div><p name="f9e6" id="f9e6" class="graf graf--p graf-after--h4">Following are four common methods of hyperparameter optimization for machine learning in order of increasing efficiency:</p><ol class="postList"><li name="3b70" id="3b70" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Manual</strong></li><li name="3074" id="3074" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Grid search</strong></li><li name="8b07" id="8b07" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Random search</strong></li><li name="f65e" id="f65e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Bayesian model-based optimization</strong></li></ol><p name="1a89" id="1a89" class="graf graf--p graf-after--li">(There are also other methods such as <a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Evolutionary_optimization" data-href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Evolutionary_optimization" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">evolutionary </a>and <a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Gradient-based_optimization" data-href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Gradient-based_optimization" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">gradient-based</a>.)</p><p name="9f95" id="9f95" class="graf graf--p graf-after--p">I was pretty proud that I’d recently moved up the ladder from manual to random search until I found this image deep in a <a href="http://proceedings.mlr.press/v28/bergstra13.pdf" data-href="http://proceedings.mlr.press/v28/bergstra13.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">paper by Bergstra et al.</a>:</p></div><div class="section-inner sectionLayout--outsetColumn"><figure name="1b8d" id="1b8d" class="graf graf--figure graf--layoutOutsetCenter graf-after--p" data-scroll="native"><div class="aspectRatioPlaceholder is-locked" style="max-width: 1000px; max-height: 355px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 35.5%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*E0_THdPH2NfKB37JUQB8Eg.png" data-width="1007" data-height="357" data-action="zoom" data-action-value="1*E0_THdPH2NfKB37JUQB8Eg.png" data-scroll="native"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_E0_THdPH2NfKB37JUQB8Eg.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="25"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*E0_THdPH2NfKB37JUQB8Eg.png" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_E0_THdPH2NfKB37JUQB8Eg(1).png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*E0_THdPH2NfKB37JUQB8Eg.png"></noscript></div></div><figcaption class="imageCaption">Validation Errors comparing random search and a model based approach on LFW (left) and PubFig83&nbsp;(right)</figcaption></figure></div><div class="section-inner sectionLayout--insetColumn"><p name="84c3" id="84c3" class="graf graf--p graf-after--figure">These figures compare validation error for hyperparameter optimization of an image classification neural network with random search in grey and Bayesian Optimization (using the Tree Parzen Estimator or TPE) in green. Lower is better: a smaller validation set error generally means better test set performance, and a smaller number of trials means less time invested. Clearly, there are significant advantages to Bayesian methods, and these graphs, along with <a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" data-href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">other impressive results,</a> convinced me it was time to take the next step and learn model-based hyperparameter optimization.</p><p name="9a9e" id="9a9e" class="graf graf--p graf-after--p">The one-sentence summary of <a href="https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf" data-href="https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Bayesian hyperparameter optimization</a> is: <span class="markup--quote markup--p-quote is-other" name="anon_a2bd98741f4f" data-creator-ids="anon">build a probability model of the objective function and use it to select the most promising hyperparameters to evaluate in the true objective function.</span></p><p name="78f8" id="78f8" class="graf graf--p graf-after--p">If you like to operate at a very high level, then this sentence may be all you need. However, if you want to understand the details, this article is my attempt to outline the concepts behind Bayesian optimization, in particular Sequential Model-Based Optimization (SMBO) with the Tree Parzen Estimator (TPE). With the mindset that you don’t know a concept until you can explain it to others, I went through <a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" data-href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">several academic</a> <a href="https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf" data-href="https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">papers</a> and will try to communicate the results in a (relatively) easy to understand format.</p><p name="3723" id="3723" class="graf graf--p graf-after--p">Although we can often implement machine learning methods without understanding how they work, I like to try and get an idea of what is going on so I can use the technique as effectively as possible. In later articles I’ll walk through using these methods in Python using libraries such as <a href="https://github.com/hyperopt/hyperopt" data-href="https://github.com/hyperopt/hyperopt" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Hyperopt</a>, so this article will lay the conceptual groundwork for implementations to come!</p><p name="aae1" id="aae1" class="graf graf--p graf-after--p graf--trailing">Update:<a href="https://github.com/WillKoehrsen/hyperparameter-optimization/blob/master/Introduction%20to%20Bayesian%20Optimization%20with%20Hyperopt.ipynb" data-href="https://github.com/WillKoehrsen/hyperparameter-optimization/blob/master/Introduction%20to%20Bayesian%20Optimization%20with%20Hyperopt.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"> Here is a brief Jupyter Notebook</a> showing the basics of using Bayesian Model-Based Optimization in the Hyperopt Python library.</p></div></div></section><section name="1b52" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="9416" id="9416" class="graf graf--h3 graf--leading">Hyperparameter Optimization</h3><p name="0b6f" id="0b6f" class="graf graf--p graf-after--h3">The aim of hyperparameter optimization in machine learning is to find the hyperparameters of a given machine learning algorithm that return the best performance as measured on a validation set. (Hyperparameters, in contrast to model parameters, are set by the machine learning engineer before training. The number of trees in a random forest is a hyperparameter while the weights in a neural network are model parameters learned during training. I like to think of hyperparameters as the model settings to be tuned.)</p><p name="91fd" id="91fd" class="graf graf--p graf-after--p">Hyperparameter optimization is represented in equation form as:</p><figure name="f259" id="f259" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 390px; max-height: 107px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 27.400000000000002%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*QR4_VOfAAWLVe2I0nqwtTg.png" data-width="390" data-height="107" data-scroll="native"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_QR4_VOfAAWLVe2I0nqwtTg.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="20"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/1*QR4_VOfAAWLVe2I0nqwtTg.png" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_QR4_VOfAAWLVe2I0nqwtTg(1).png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/1*QR4_VOfAAWLVe2I0nqwtTg.png"></noscript></div></div></figure><p name="2c27" id="2c27" class="graf graf--p graf-after--figure">Here f(x) represents an objective score to minimize— such as RMSE or error rate— evaluated on the validation set; x* is the set of hyperparameters that yields the lowest value of the score, and x can take on any value in the domain X. In simple terms, we want to <strong class="markup--strong markup--p-strong">find the model hyperparameters that yield the best score on the validation set metric</strong>.</p><p name="bd05" id="bd05" class="graf graf--p graf-after--p">The problem with hyperparameter optimization is that evaluating the objective function to find the score is extremely expensive. Each time we try different hyperparameters, we have to train a model on the training data, make predictions on the validation data, and then calculate the validation metric. With a large number of hyperparameters and complex models such as ensembles or deep neural networks that can take days to train, this process quickly becomes intractable to do by hand!</p><p name="f6db" id="f6db" class="graf graf--p graf-after--p">Grid search and <a href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf" data-href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">random search are slightly better</a> than manual tuning because we set up a grid of model hyperparameters and run the train-predict -evaluate cycle automatically in a loop while we do more productive things (like<a href="https://www.featuretools.com/" data-href="https://www.featuretools.com/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"> feature engineering</a>). However, even these methods are relatively inefficient because they do not choose the next hyperparameters to evaluate based on previous results. <strong class="markup--strong markup--p-strong">Grid and random search are completely <em class="markup--em markup--p-em">uninformed </em>by past evaluations, </strong>and as a result, often spend a significant amount of time evaluating “bad” hyperparameters.</p><p name="c268" id="c268" class="graf graf--p graf-after--p">For example, if we have the following graph with a lower score being better, where does it make sense to concentrate our search? If you said below 200 estimators, then you already have the idea of Bayesian optimization! We want to focus on the most promising hyperparameters, and if we have a record of evaluations, then it makes sense to use this information for our next choice.</p><figure name="2a47" id="2a47" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 560px; max-height: 427px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 76.3%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*MiNXGrkk5BbjfkNAXZQSNA.png" data-width="560" data-height="427" data-scroll="native"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_MiNXGrkk5BbjfkNAXZQSNA.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="55"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/1*MiNXGrkk5BbjfkNAXZQSNA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/1*MiNXGrkk5BbjfkNAXZQSNA.png"></noscript></div></div></figure><p name="d0b1" id="d0b1" class="graf graf--p graf-after--figure">Random and grid search pay no attention to past results at all and would keep searching across the entire range of the number of estimators even though it’s clear the optimal answer (probably) lies in a small region!</p><h3 name="9dd0" id="9dd0" class="graf graf--h3 graf-after--p">Bayesian Optimization</h3><p name="d777" id="d777" class="graf graf--p graf-after--h3"><a href="https://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf" data-href="https://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Bayesian approaches</a>, in contrast to random or grid search, keep track of past evaluation results which they use to form a probabilistic model mapping hyperparameters to a probability of a score on the objective function:</p><figure name="c080" id="c080" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 307px; max-height: 58px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 18.9%;"></div><img class="graf-image" data-image-id="1*u00KlxHhd1fz6-Jaeou6PA.png" data-width="307" data-height="58" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_u00KlxHhd1fz6-Jaeou6PA.png"></div></figure><p name="1ab2" id="1ab2" class="graf graf--p graf-after--figure"><a href="https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf" data-href="https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">In the literature</a>, this model is called a “surrogate” for the objective function and is represented as p(y | x). The surrogate is much easier to optimize than the objective function and Bayesian methods work by finding the next set of hyperparameters to evaluate on the actual objective function by selecting hyperparameters that perform best on the surrogate function. In other words:</p><ol class="postList"><li name="db12" id="db12" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Build a surrogate probability model of the objective function</strong></li><li name="5cb5" id="5cb5" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Find the hyperparameters that perform best on the surrogate</strong></li><li name="07a9" id="07a9" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Apply these hyperparameters to the true objective function</strong></li><li name="e350" id="e350" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Update the surrogate model incorporating the new results</strong></li><li name="f18d" id="f18d" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Repeat steps 2–4 until max iterations or time is reached</strong></li></ol><p name="b823" id="b823" class="graf graf--p graf-after--li">The<a href="https://towardsdatascience.com/bayes-rule-applied-75965e4482ff" data-href="https://towardsdatascience.com/bayes-rule-applied-75965e4482ff" class="markup--anchor markup--p-anchor" target="_blank"> aim of Bayesian reasoning is to become “less wrong” with more data</a> which these approaches do by continually updating the surrogate probability model after each evaluation of the objective function.</p><p name="9fac" id="9fac" class="graf graf--p graf-after--p">At a high-level, Bayesian optimization methods are efficient because they choose the next hyperparameters in an <em class="markup--em markup--p-em">informed manner</em><strong class="markup--strong markup--p-strong">. </strong>The basic idea is: <strong class="markup--strong markup--p-strong">spend a little more time selecting the next hyperparameters in order to make fewer calls to the objective function.</strong> In practice, the time spent selecting the next hyperparameters is inconsequential compared to the time spent in the objective function. By evaluating hyperparameters that appear more promising from past results, Bayesian methods can find better model settings than random search in fewer iterations.</p><p name="f3ee" id="f3ee" class="graf graf--p graf-after--p">If there’s one thing to take away from this article it’s that <a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Bayesian_optimization" data-href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Bayesian_optimization" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Bayesian model-based methods</a> can find better hyperparameters in less time because they reason about the best set of hyperparameters to evaluate based on past trials.</p><p name="6e58" id="6e58" class="graf graf--p graf-after--p">As a good visual description of what is occurring in Bayesian Optimization take a look at the images below (<a href="https://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf" data-href="https://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">source</a>). The first shows an initial estimate of the surrogate model — in black with associated uncertainty in gray — after two evaluations. Clearly, the surrogate model is a poor approximation of the actual objective function in red:</p><figure name="4356" id="4356" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 341px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 48.699999999999996%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*RQ-pAwQ88yC904QppChGPQ.png" data-width="1307" data-height="637" data-action="zoom" data-action-value="1*RQ-pAwQ88yC904QppChGPQ.png" data-scroll="native"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_RQ-pAwQ88yC904QppChGPQ.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="35"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/1*RQ-pAwQ88yC904QppChGPQ.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/1*RQ-pAwQ88yC904QppChGPQ.png"></noscript></div></div></figure><p name="7ef0" id="7ef0" class="graf graf--p graf-after--figure">The next image shows the surrogate function after 8 evaluations. Now the surrogate almost exactly matches the true function. Therefore, if the algorithm selects the hyperparameters that maximize the surrogate, they will likely yield very good results on the true evaluation function.</p><figure name="1bac" id="1bac" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 336px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 48%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*bSLAe1LCj3mMKfaZsQWCrw.png" data-width="1314" data-height="631" data-action="zoom" data-action-value="1*bSLAe1LCj3mMKfaZsQWCrw.png" data-scroll="native"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_bSLAe1LCj3mMKfaZsQWCrw.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="35"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/1*bSLAe1LCj3mMKfaZsQWCrw.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/1*bSLAe1LCj3mMKfaZsQWCrw.png"></noscript></div></div></figure><p name="0f1c" id="0f1c" class="graf graf--p graf-after--figure graf--trailing">Bayesian methods have always made sense to me because they operate in much the same way we do: we form an initial view of the world (called a prior) and then we update our model based on new experiences (the updated model is called a posterior). Bayesian hyperparameter optimization takes that framework and applies it to finding the best value of model settings!</p></div></div></section><section name="31de" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h4 name="4c1f" id="4c1f" class="graf graf--h4 graf--leading">Sequential Model-Based Optimization</h4><p name="b68b" id="b68b" class="graf graf--p graf-after--h4"><a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" data-href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Sequential model-based optimization (SMBO) methods (SMBO)</a> are a formalization of Bayesian optimization. The sequential refers to running trials one after another, each time trying better hyperparameters by applying Bayesian reasoning and updating a probability model (surrogate).</p><p name="6cfd" id="6cfd" class="graf graf--p graf-after--p">There are five aspects of model-based hyperparameter optimization:</p><ol class="postList"><li name="e3d1" id="e3d1" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">A domain of hyperparameters over which to search</strong></li><li name="0434" id="0434" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">An objective function which takes in hyperparameters and outputs a score that we want to minimize (or maximize)</strong></li><li name="c1ce" id="c1ce" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">The surrogate model of the objective function</strong></li><li name="1c77" id="1c77" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">A criteria, called a selection function, for evaluating which hyperparameters to choose next from the surrogate model</strong></li><li name="5352" id="5352" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">A history consisting of (score, hyperparameter) pairs used by the algorithm to update the surrogate model</strong></li></ol><p name="417e" id="417e" class="graf graf--p graf-after--li">There are several variants of <a href="https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf" data-href="https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">SMBO methods that differ</a> in steps 3–4, namely, how they build a surrogate of the objective function and the criteria used to select the next hyperparameters. Several common choices for the surrogate model are <a href="https://en.wikipedia.org/wiki/Gaussian_process" data-href="https://en.wikipedia.org/wiki/Gaussian_process" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Gaussian Processes</a>, <a href="http://aad.informatik.uni-freiburg.de/papers/13-GECCO-BBOB_SMAC.pdf" data-href="http://aad.informatik.uni-freiburg.de/papers/13-GECCO-BBOB_SMAC.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Random Forest Regressions</a>, and Tree Parzen Estimators (TPE) while the most common choice for step 4 is Expected Improvement. In this post, we will focus on TPE and Expected Improvement.</p><h4 name="fa1c" id="fa1c" class="graf graf--h4 graf-after--p">Domain</h4><p name="d91e" id="d91e" class="graf graf--p graf-after--h4">In the case of random search and grid search, the domain of hyperparameters we search is a grid. An example for a random forest is shown below:</p><figure name="7ae2" id="7ae2" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 21%;"></div><div class="iframeContainer"><iframe width="700" height="250" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/f6b581f613ecd6038d020b40a585335f.html" data-media-id="f6b581f613ecd6038d020b40a585335f" allowfullscreen="" frameborder="0"></iframe></div></div></figure><p name="1b0a" id="1b0a" class="graf graf--p graf-after--figure">For a model-based approach, the domain consists of <em class="markup--em markup--p-em">probability distributions</em>. As with a grid, this lets us encode domain knowledge into the search process by placing greater probability in regions where we think the true best hyperparameters lie. If we wanted to express the above grid as a probability distribution, it may look something like this:</p></div><div class="section-inner sectionLayout--outsetRow" data-paragraph-count="3"><figure name="0baa" id="0baa" class="graf graf--figure graf--layoutOutsetRow is-partialWidth graf-after--p" style="width: 34.614%;" data-scroll="native"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.4%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*luY6Ahh7uttR4quIcgOCBw.png" data-width="420" data-height="279" data-action="zoom" data-action-value="1*luY6Ahh7uttR4quIcgOCBw.png" data-scroll="native"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_luY6Ahh7uttR4quIcgOCBw.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="47"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/400/1*luY6Ahh7uttR4quIcgOCBw.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/400/1*luY6Ahh7uttR4quIcgOCBw.png"></noscript></div></div></figure><figure name="c5f4" id="c5f4" class="graf graf--figure graf--layoutOutsetRowContinue is-partialWidth graf-after--figure" style="width: 32.82%;" data-scroll="native"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 70.1%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*YfoPLKK8_WXIsRaQ7zcSjg.png" data-width="398" data-height="279" data-action="zoom" data-action-value="1*YfoPLKK8_WXIsRaQ7zcSjg.png" data-scroll="native"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_YfoPLKK8_WXIsRaQ7zcSjg.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="52"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/400/1*YfoPLKK8_WXIsRaQ7zcSjg.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/400/1*YfoPLKK8_WXIsRaQ7zcSjg.png"></noscript></div></div></figure><figure name="b133" id="b133" class="graf graf--figure graf--layoutOutsetRowContinue is-partialWidth graf-after--figure" style="width: 32.567%;" data-scroll="native"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 70.6%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*e6cIETdFd1rzD9ivofNJqw.png" data-width="395" data-height="279" data-action="zoom" data-action-value="1*e6cIETdFd1rzD9ivofNJqw.png" data-scroll="native"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_e6cIETdFd1rzD9ivofNJqw.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="52"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/400/1*e6cIETdFd1rzD9ivofNJqw.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/400/1*e6cIETdFd1rzD9ivofNJqw.png"></noscript></div></div></figure></div><div class="section-inner sectionLayout--insetColumn"><p name="4528" id="4528" class="graf graf--p graf-after--figure">Here we have a uniform, log-normal, and normal distribution. These are informed by prior practice/knowledge (for example the <a href="https://www.kdnuggets.com/2017/11/estimating-optimal-learning-rate-deep-neural-network.html" data-href="https://www.kdnuggets.com/2017/11/estimating-optimal-learning-rate-deep-neural-network.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">learning rate domain is usually a log-normal distribution over several orders of magnitude</a>).</p><h4 name="56a8" id="56a8" class="graf graf--h4 graf-after--p">Objective Function</h4><p name="e473" id="e473" class="graf graf--p graf-after--h4">The objective function takes in hyperparameters and outputs a single real-valued score that we want to minimize (or maximize). As an example, let’s consider the case of building a random forest for a regression problem. The hyperparameters we want to optimize are shown in the hyperparameter grid above and the score to minimize is the Root Mean Squared Error. Our objective function would then look like (in Python):</p><figure name="a3b0" id="a3b0" class="graf graf--figure graf--iframe graf-after--p"><div class="aspectRatioPlaceholder is-locked"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 58.714%;"></div><div class="iframeContainer"><iframe width="700" height="250" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/eb66de79843c965b04a82826e9c4416c.html" data-media-id="eb66de79843c965b04a82826e9c4416c" allowfullscreen="" frameborder="0"></iframe></div></div></figure><p name="8316" id="8316" class="graf graf--p graf-after--figure">While the objective function looks simple, it is very expensive to compute! If the objective function could be quickly calculated, then we could try every single possible hyperparameter combination (like in grid search). If we are using a simple model, a small hyperparameter grid, and a small dataset, then this might be the best way to go. However, in cases where the objective function may take hours or even days to evaluate, we want to limit calls to it.</p><p name="efea" id="efea" class="graf graf--p graf-after--p">The entire concept of Bayesian model-based optimization is to reduce the number of times the objective function needs to be run by choosing only the most promising set of hyperparameters to evaluate based on previous calls to the evaluation function. The next set of hyperparameters are selected based on a model of the objective function called a surrogate.</p><h4 name="d36e" id="d36e" class="graf graf--h4 graf-after--p">Surrogate Function (Probability Model)</h4><p name="104e" id="104e" class="graf graf--p graf-after--h4">The surrogate function, also called the response surface, is the probability representation of the objective function built using previous evaluations. This is called sometimes called a response surface because it is a high-dimensional mapping of hyperparameters to the probability of a score on the objective function. Below is a simple example with only two hyperparameters:</p><figure name="9e7b" id="9e7b" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 480px; max-height: 480px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 100%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="0*aBsprZzniYMB0KWc.png" data-width="480" data-height="480" data-scroll="native"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/0_aBsprZzniYMB0KWc.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="75"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/0*aBsprZzniYMB0KWc.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/0*aBsprZzniYMB0KWc.png"></noscript></div></div><figcaption class="imageCaption">Response surface for AdaBoost algorithm (<a href="http://www.hylap.org/meta_data/adaboost/" data-href="http://www.hylap.org/meta_data/adaboost/" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Source</a>)</figcaption></figure><p name="4bf1" id="4bf1" class="graf graf--p graf-after--figure">There are several different forms of the surrogate function including Gaussian Processes and Random Forest regression. However, in this post we will focus on the Tree-structured Parzen Estimator as <a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" data-href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">put forward by Bergstra et al</a> in the paper “Algorithms for Hyper-Parameter Optimization”. These methods differ in how they construct the surrogate function which we’ll explain in just a bit. First we need to talk about the selection function.</p><h4 name="e1b4" id="e1b4" class="graf graf--h4 graf-after--p">Selection Function</h4><p name="cbc5" id="cbc5" class="graf graf--p graf-after--h4">The selection function is the criteria by which the next set of hyperparameters are chosen from the surrogate function. The most common choice of criteria is Expected Improvement:</p><figure name="1df3" id="1df3" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 358px; max-height: 83px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 23.200000000000003%;"></div><img class="graf-image" data-image-id="1*ebsqjhOTSGKBbIR_RLkjSQ.png" data-width="358" data-height="83" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_ebsqjhOTSGKBbIR_RLkjSQ.png"></div></figure><p name="6c7d" id="6c7d" class="graf graf--p graf-after--figure">Here y* is a threshold value of the objective function, x is the proposed set of hyperparameters, y is the actual value of the objective function using hyperparameters x, and p(y | x) is the surrogate probability model expressing the probability of y given x. If that’s all a little much, in simpler terms, <strong class="markup--strong markup--p-strong">the aim is to maximize the Expected Improvement with respect to x.</strong> This means finding the best hyperparameters under the surrogate function p (y | x).</p><p name="044b" id="044b" class="graf graf--p graf-after--p graf--trailing">If p (y | x) is zero everywhere that y &lt; y*, then the hyperparameters x are not expected to yield any improvement. If the integral is positive, then it means that the hyperparameters x are expected to yield a better result than the threshold value.</p></div></div></section><section name="0fe7" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="eba6" id="eba6" class="graf graf--p graf--leading"><strong class="markup--strong markup--p-strong">Tree-structured Parzen Estimator (TPE)</strong></p><p name="118f" id="118f" class="graf graf--p graf-after--p">Now let’s get back to the surrogate function. The methods of SMBO differ in how they construct the surrogate model p(y | x). The Tree-structured Parzen Estimator builds a model by applying Bayes rule. Instead of directly representing p( y | x), it instead uses:</p><figure name="68f2" id="68f2" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 256px; max-height: 81px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 31.6%;"></div><img class="graf-image" data-image-id="1*4D1QpDZzWpBOl7ANBhsSJA.png" data-width="256" data-height="81" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_4D1QpDZzWpBOl7ANBhsSJA.png"></div><figcaption class="imageCaption">Bayes Rule in&nbsp;Action!</figcaption></figure><p name="0f29" id="0f29" class="graf graf--p graf-after--figure">p (x | y), which is the probability of the hyperparameters given the score on the objective function, in turn is expressed:</p><figure name="34a1" id="34a1" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 291px; max-height: 80px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 27.500000000000004%;"></div><img class="graf-image" data-image-id="1*idWxsGylqq2ZaMGpHmbxDg.png" data-width="291" data-height="80" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_idWxsGylqq2ZaMGpHmbxDg.png"></div></figure><p name="a37c" id="a37c" class="graf graf--p graf-after--figure">where y &lt; y* represents a lower value of the objective function than the threshold. The explanation of this equation is that we make <em class="markup--em markup--p-em">two different distributions for the hyperparameters</em>: one where the value of the objective function is less than the threshold, <em class="markup--em markup--p-em">l(x),</em> and one where the value of the objective function is greater than the threshold, <em class="markup--em markup--p-em">g(x)</em>.</p><p name="26ba" id="26ba" class="graf graf--p graf-after--p">Let’s update our Random Forest graph to include a threshold:</p><figure name="1c5e" id="1c5e" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 560px; max-height: 427px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 76.3%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*H5pyf3G115WGJwPpg65yaQ.png" data-width="560" data-height="427" data-scroll="native"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_H5pyf3G115WGJwPpg65yaQ.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="55"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/1*H5pyf3G115WGJwPpg65yaQ.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/1*H5pyf3G115WGJwPpg65yaQ.png"></noscript></div></div></figure><p name="ab03" id="ab03" class="graf graf--p graf-after--figure">Now we construct two probability distributions for the number of estimators, one using the estimators that yielded values under the threshold and one using the estimators that yielded values above the threshold.</p><figure name="6541" id="6541" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 580px; max-height: 425px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 73.3%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded" data-image-id="1*6SH5O_ail54karro8j0NGg.png" data-width="580" data-height="425" data-scroll="native"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_6SH5O_ail54karro8j0NGg.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="52"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/800/1*6SH5O_ail54karro8j0NGg.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/800/1*6SH5O_ail54karro8j0NGg.png"></noscript></div></div></figure><p name="53c0" id="53c0" class="graf graf--p graf-after--figure">Intuitively, it seems that we want to draw values of x from <em class="markup--em markup--p-em">l(x) </em>and not from <em class="markup--em markup--p-em">g(x) </em>because this distribution is based only on values of x that yielded lower scores than the threshold. It turns out this is exactly what the math says as well! With Bayes Rule, and a few substitutions, the expected improvement equation (which we are trying to maximize) becomes:</p><figure name="1d0d" id="1d0d" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 623px; max-height: 62px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 10%;"></div><img class="graf-image" data-image-id="1*ybiePL_8lKNouHlSb5OSgQ.png" data-width="623" data-height="62" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_ybiePL_8lKNouHlSb5OSgQ.png"></div></figure><p name="f1f6" id="f1f6" class="graf graf--p graf-after--figure">The term on the far right is the most important part. What this says is that the <a href="https://www.cse.wustl.edu/~garnett/cse515t/spring_2015/files/lecture_notes/12.pdf" data-href="https://www.cse.wustl.edu/~garnett/cse515t/spring_2015/files/lecture_notes/12.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Expected Improvement</a> is proportional to the ratio <em class="markup--em markup--p-em">l(x) / g(x) </em>and therefore, to maximize the Expected Improvement, we should maximize this ratio. Our intuition was correct: we should draw values of the hyperparameters which are more likely under <em class="markup--em markup--p-em">l(x) </em>than under <em class="markup--em markup--p-em">g(x)</em>!</p><p name="f5c5" id="f5c5" class="graf graf--p graf-after--p">The Tree-structured Parzen Estimator works by drawing sample hyperparameters from <em class="markup--em markup--p-em">l(x)</em>, evaluating them in terms of <em class="markup--em markup--p-em">l(x) / g(x)</em>, and returning the set that yields the highest value under <em class="markup--em markup--p-em">l(x) / g(x) </em>corresponding to the greatest expected improvement<em class="markup--em markup--p-em">. </em>These hyperparameters are then evaluated on the objective function. If the surrogate function is correct, then these hyperparameters should yield a better value when evaluated!</p><p name="4c81" id="4c81" class="graf graf--p graf-after--p">The expected improvement criteria allows the model to balance <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit" data-href="https://en.wikipedia.org/wiki/Multi-armed_bandit" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">exploration versus exploitation</a>. <em class="markup--em markup--p-em">l(x)</em> is a distribution and not a single value which means that the hyperparameters drawn are likely close but not exactly at the maximum of the expected improvement. Moreover, because the surrogate is just an estimate of the objective function, the selected hyperparameters may not actually yield an improvement when evaluated and the surrogate model will have to be updated. This updating is done based on the current surrogate model and the history of objective function evaluations.</p><h4 name="6b66" id="6b66" class="graf graf--h4 graf-after--p">History</h4><p name="e80c" id="e80c" class="graf graf--p graf-after--h4">Each time the algorithm proposes a new set of candidate hyperparameters, it evaluates them with the actual objective function and records the result in a pair (score, hyperparameters). These records form the<strong class="markup--strong markup--p-strong"> history</strong>. The algorithm builds <em class="markup--em markup--p-em">l(x) </em>and <em class="markup--em markup--p-em">g(x) </em>using the history to come up with a probability model of the objective function that improves with each iteration.</p><p name="2f9f" id="2f9f" class="graf graf--p graf-after--p"><a href="https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7" data-href="https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7" class="markup--anchor markup--p-anchor" target="_blank">This is Bayes’ Rule at work</a>: we have an initial estimate for the surrogate of the objective function that we update as we gather more evidence. Eventually, with enough evaluations of the objective function, we hope that our model accurately reflects the objective function and the hyperparameters that yield the greatest Expected Improvement correspond to the hyperparameters that maximize the objective function.</p><h3 name="3261" id="3261" class="graf graf--h3 graf-after--p"><strong class="markup--strong markup--h3-strong">Putting it All&nbsp;Together</strong></h3><p name="83dc" id="83dc" class="graf graf--p graf-after--h3">How do Sequential Model-Based Methods help us more efficiently search the hyperparameter space? Because the algorithm is proposing better candidate hyperparameters for evaluation, the score on the objective function improves much more rapidly than with random or grid search leading to fewer overall evaluations of the objective function.</p><p name="ff4b" id="ff4b" class="graf graf--p graf-after--p">Even though the algorithm spends more time selecting the next hyperparameters by maximizing the Expected Improvement, this is much cheaper in terms of computational cost than evaluating the objective function. <a href="http://proceedings.mlr.press/v28/bergstra13.pdf" data-href="http://proceedings.mlr.press/v28/bergstra13.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">In a paper about using SMBO with TPE</a>, the authors reported that finding the next proposed set of candidate hyperparameters took several seconds, while evaluating the actual objective function took hours.</p><p name="86a5" id="86a5" class="graf graf--p graf-after--p">If we are using better-informed methods to choose the next hyperparameters, that means we can spend less time evaluating poor hyperparameter choices. Furthermore, sequential model-based optimization using tree-structured Parzen estimators is able to find better hyperparameters than random search in the same number of trials. In other words, we get</p><ul class="postList"><li name="a9f8" id="a9f8" class="graf graf--li graf-after--p">Reduced running time of hyperparameter tuning</li><li name="1411" id="1411" class="graf graf--li graf-after--li">Better scores on the testing set</li></ul><p name="946e" id="946e" class="graf graf--p graf-after--li">Hopefully, this has convinced you Bayesian model-based optimization is a technique worth trying!</p><h4 name="59f5" id="59f5" class="graf graf--h4 graf-after--p">Implementation</h4><p name="d075" id="d075" class="graf graf--p graf-after--h4 graf--trailing">Fortunately for us, there are now a number of libraries that can do SMBO in Python. <a href="https://github.com/JasperSnoek/spearmint" data-href="https://github.com/JasperSnoek/spearmint" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Spearmint </a>and <a href="https://github.com/Yelp/MOE" data-href="https://github.com/Yelp/MOE" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">MOE</a> use a Gaussian Process for the surrogate, <a href="https://github.com/hyperopt/hyperopt" data-href="https://github.com/hyperopt/hyperopt" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Hyperopt</a> uses the Tree-structured Parzen Estimator, and <a href="https://github.com/automl/SMAC3" data-href="https://github.com/automl/SMAC3" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">SMAC</a> uses a Random Forest regression. These libraries all use the Expected Improvement criterion to select the next hyperparameters from the surrogate model. In later articles we will take a look at using Hyperopt in Python and there are already<a href="http://fastml.com/optimizing-hyperparams-with-hyperopt/" data-href="http://fastml.com/optimizing-hyperparams-with-hyperopt/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"> several </a><a href="https://github.com/jaberg/hyperopt/wiki/FMin" data-href="https://github.com/jaberg/hyperopt/wiki/FMin" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">good</a> articles and <a href="https://www.programcreek.com/python/example/98788/hyperopt.Trials" data-href="https://www.programcreek.com/python/example/98788/hyperopt.Trials" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">code examples</a> for learning.</p></div></div></section><section name="3e39" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="c119" id="c119" class="graf graf--h3 graf--leading">Conclusions</h3><p name="48a7" id="48a7" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">Bayesian model-based optimization methods build a probability model of the objective function to propose smarter choices for the next set of hyperparameters to evaluate. SMBO is a formalization of Bayesian optimization which is more efficient at finding the best hyperparameters for a machine learning model than random or grid search.</strong></p><p name="13b7" id="13b7" class="graf graf--p graf-after--p">Sequential model-based optimization methods differ in they build the surrogate, but they all rely on information from previous trials to propose better hyperparameters for the next evaluation. The Tree Parzen Estimator is one algorithm that uses Bayesian reasoning to construct the surrogate model and can select the next hyperparameters using Expected Improvement.</p><p name="05b7" id="05b7" class="graf graf--p graf-after--p">There are a number of libraries to implement SMBO in Python which we will explore in further articles. The concepts are a little tough at first, but understanding them will allow us to use the tools built on them more effectively. I’d like to mention I’m still trying to work my way through the details and if I’ve made a mistake, please let me know (civilly)!</p><p name="1eed" id="1eed" class="graf graf--p graf-after--p">For more details, the following articles are extremely helpful:</p><ol class="postList"><li name="0fdc" id="0fdc" class="graf graf--li graf-after--p">Algorithms for Hyper-Parameter Optimization [<a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" data-href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Link</a>]</li><li name="b3aa" id="b3aa" class="graf graf--li graf-after--li">Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures [<a href="http://proceedings.mlr.press/v28/bergstra13.pdf" data-href="http://proceedings.mlr.press/v28/bergstra13.pdf" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Link</a>]</li><li name="dcdf" id="dcdf" class="graf graf--li graf-after--li">Bayesian Optimization Primer [<a href="https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf" data-href="https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Link</a>]</li><li name="4b47" id="4b47" class="graf graf--li graf-after--li">Taking the Human Out of the Loop: A Review of Bayesian Optimization [<a href="https://www.cs.ox.ac.uk/people/nando.defreitas/publications/BayesOptLoop.pdf" data-href="https://www.cs.ox.ac.uk/people/nando.defreitas/publications/BayesOptLoop.pdf" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Link</a>]</li></ol><p name="ce5f" id="ce5f" class="graf graf--p graf-after--li graf--trailing">As always, I welcome feedback and constructive criticism. I can be reached on Twitter <a href="http://twitter.com/@koehrsen_will" data-href="http://twitter.com/@koehrsen_will" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">@koehrsen_will</a></p></div></div></section></div><footer class="u-paddingTop10"><div class="container u-maxWidth740"><div class="row"><div class="col u-size12of12"></div></div><div class="row"><div class="col u-size12of12 js-postTags"><div class="u-paddingBottom10"><ul class="tags tags--postTags tags--borderless"><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/machine-learning?source=post" data-action-source="post" data-collection-slug="towards-data-science">Machine Learning</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/education?source=post" data-action-source="post" data-collection-slug="towards-data-science">Education</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/bayesian-machine-learning?source=post" data-action-source="post" data-collection-slug="towards-data-science">Bayesian Machine Learning</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/computer-science?source=post" data-action-source="post" data-collection-slug="towards-data-science">Computer Science</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/towards-data-science?source=post" data-action-source="post" data-collection-slug="towards-data-science">Towards Data Science</a></li></ul></div></div></div><div class="postActions js-postActionsFooter "><div class="u-flexCenter"><div class="u-flex1"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="b8172278050f" data-is-icon-29px="true" data-is-circle="true" data-has-recommend-list="true" data-source="post_actions_footer-----b8172278050f---------------------clap_footer" data-clap-string-singular="clap" data-clap-string-plural="claps"><div class="u-relative u-foreground"><button class="button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal clap-onboardingcollection clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/b8172278050f" data-action-source="post_actions_footer-----b8172278050f---------------------clap_footer" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33"><path d="M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33"><g fill-rule="evenodd"><path d="M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z"></path><path d="M13.285.48l-1.916.881 2.37 2.837z"></path><path d="M21.719 1.361L19.79.501l-.44 3.697z"></path><path d="M16.502 3.298L15.481 0h2.043z"></path></g></svg></span></span></button><div class="clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Spring u-backgroundGrayLighter js-clapUndo" style="top: 14px; padding: 2px;"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight" data-action="multivote-undo" data-action-value="b8172278050f"><span class="svgIcon svgIcon--removeThin svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61" fill-rule="evenodd"></path></svg></span></button></div></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft10 u-marginLeft16"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-textColorDarker" data-action="show-recommends" data-action-value="b8172278050f">2.2K claps</button><span class="u-xs-hide"></span></span></div></div><div class="buttonSet u-flex0"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-hide u-marginRight12" title="Share on Twitter" aria-label="Share on Twitter" data-action="share-on-twitter" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--twitterFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M22.053 7.54a4.474 4.474 0 0 0-3.31-1.455 4.526 4.526 0 0 0-4.526 4.524c0 .35.04.7.082 1.05a12.9 12.9 0 0 1-9.3-4.77c-.39.69-.61 1.46-.65 2.26.03 1.6.83 2.99 2.02 3.79-.72-.02-1.41-.22-2.02-.57-.01.02-.01.04 0 .08-.01 2.17 1.55 4 3.63 4.44-.39.08-.79.13-1.21.16-.28-.03-.57-.05-.81-.08.54 1.77 2.21 3.08 4.2 3.15a9.564 9.564 0 0 1-5.66 1.94c-.34-.03-.7-.06-1.05-.08 2 1.27 4.38 2.02 6.94 2.02 8.31 0 12.86-6.9 12.84-12.85.02-.24.01-.43 0-.65.89-.62 1.65-1.42 2.26-2.34-.82.38-1.69.62-2.59.72a4.37 4.37 0 0 0 1.94-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-hide u-marginRight12" title="Share on Facebook" aria-label="Share on Facebook" data-action="share-on-facebook" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--facebookSquare svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M23.209 5H5.792A.792.792 0 0 0 5 5.791V23.21c0 .437.354.791.792.791h9.303v-7.125H12.72v-2.968h2.375v-2.375c0-2.455 1.553-3.662 3.741-3.662 1.049 0 1.95.078 2.213.112v2.565h-1.517c-1.192 0-1.469.567-1.469 1.397v1.963h2.969l-.594 2.968h-2.375L18.11 24h5.099a.791.791 0 0 0 .791-.791V5.79a.791.791 0 0 0-.791-.79"></path></svg></span></button><button class="button button--large button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-show u-marginRight10" title="Share this story on Twitter or Facebook" aria-label="Share this story on Twitter or Facebook" data-action="show-share-popover" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--share svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M20.385 8H19a.5.5 0 1 0 .011 1h1.39c.43 0 .84.168 1.14.473.31.305.48.71.48 1.142v10.77c0 .43-.17.837-.47 1.142-.3.305-.71.473-1.14.473H8.62c-.43 0-.84-.168-1.144-.473a1.603 1.603 0 0 1-.473-1.142v-10.77c0-.43.17-.837.48-1.142A1.599 1.599 0 0 1 8.62 9H10a.502.502 0 0 0 0-1H8.615c-.67 0-1.338.255-1.85.766-.51.51-.765 1.18-.765 1.85v10.77c0 .668.255 1.337.766 1.848.51.51 1.18.766 1.85.766h11.77c.668 0 1.337-.255 1.848-.766.51-.51.766-1.18.766-1.85v-10.77c0-.668-.255-1.337-.766-1.848A2.61 2.61 0 0 0 20.384 8zm-8.67-2.508L14 3.207v8.362c0 .27.224.5.5.5s.5-.23.5-.5V3.2l2.285 2.285a.49.49 0 0 0 .704-.001.511.511 0 0 0 0-.708l-3.14-3.14a.504.504 0 0 0-.71 0L11 4.776a.501.501 0 0 0 .71.706" fill-rule="evenodd"></path></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" data-action="scroll-to-responses" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal u-marginRight12" data-action="scroll-to-responses">7</button><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/b8172278050f" data-action-source="post_actions_footer"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px u-marginRight4"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px u-marginRight4"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"></path></svg></span></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon js-moreActionsButton" title="More actions" aria-label="More actions" data-action="more-actions"><span class="svgIcon svgIcon--more svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="-480.5 272.5 21 21"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></span></button></div></div></div></div><div class="u-maxWidth740 u-paddingTop20 u-marginTop20 u-borderTopLightest container u-paddingBottom20 u-xs-paddingBottom10 js-postAttributionFooterContainer"><div class="row js-postFooterInfo"><div class="col u-size6of12 u-xs-size12of12"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardUser"><div class="u-marginLeft20 u-floatRight"><span class="followState js-followState" data-user-id="e2f299e30cb9"><button class="button button--small u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f" data-action-source="footer_card"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/e2f299e30cb9" data-action-source="footer_card-e2f299e30cb9-------------------------follow_footer"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="u-tableCell"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@williamkoehrsen?source=footer_card" title="Go to the profile of Will Koehrsen" aria-label="Go to the profile of Will Koehrsen" data-action-source="footer_card" data-user-id="e2f299e30cb9" data-collection-slug="towards-data-science" dir="auto"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_SckxdIFfjlR-cWXkL5ya-g(1).jpeg" class="avatar-image avatar-image--small" alt="Go to the profile of Will Koehrsen"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://towardsdatascience.com/@williamkoehrsen" property="cc:attributionName" title="Go to the profile of Will Koehrsen" aria-label="Go to the profile of Will Koehrsen" rel="author cc:attributionUrl" data-user-id="e2f299e30cb9" data-collection-slug="towards-data-science" dir="auto">Will Koehrsen</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">Data Scientist at Cortex Intel, Data Science Communicator</p></div></li></div><div class="col u-size6of12 u-xs-size12of12 u-xs-marginTop30"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardCollection"><div class="u-marginLeft20 u-floatRight"><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton" data-action="sign-up-prompt" data-sign-in-action="toggle-follow-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/towards-data-science" data-action-source="----7f60cf5620c9----------------------follow_footer" data-collection-id="7f60cf5620c9"><span class="button-label  js-buttonLabel">Follow</span></button></div><div class="u-tableCell "><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://towardsdatascience.com/?source=footer_card" title="Go to Towards Data Science" aria-label="Go to Towards Data Science" data-action-source="footer_card" data-collection-slug="towards-data-science"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_F0LADxTtsKOgmPa-_7iUEQ.jpeg" class="avatar-image u-size60x60" alt="Towards Data Science"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://towardsdatascience.com/?source=footer_card" rel="collection" data-action-source="footer_card" data-collection-slug="towards-data-science">Towards Data Science</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">Sharing concepts, ideas, and codes.</p><div class="buttonSet"></div></div></li></div></div></div><div class="js-postFooterPlacements"><div class="streamItem streamItem--placementCardGrid js-streamItem"><div class="u-clearfix u-backgroundGrayLightest"><div class="row u-marginAuto u-maxWidth1000 u-paddingTop30 u-paddingBottom40"><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-width100pct u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackedPost" data-post-id="a581dce1f5fc" data-source="placement_card_footer_grid---------0-41" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://towardsdatascience.com/why-you-should-care-about-the-nate-silver-vs-nassim-taleb-twitter-war-a581dce1f5fc?source=placement_card_footer_grid---------0-41" data-action-source="placement_card_footer_grid---------0-41"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-width100pct u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/1*D_tidaT-fHMY3DRLgjwekw.png&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://towardsdatascience.com/why-you-should-care-about-the-nate-silver-vs-nassim-taleb-twitter-war-a581dce1f5fc?source=placement_card_footer_grid---------0-41" data-action-source="placement_card_footer_grid---------0-41"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from Towards Data Science</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Why you should care about the Nate Silver vs. Nassim Taleb Twitter war</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@isaacfaber" data-action="show-user-card" data-action-value="81d6b9acba62" data-action-type="hover" data-user-id="81d6b9acba62" data-collection-slug="towards-data-science" dir="auto"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_oQEv0ES7AUPNp-zPsIOKkw.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Isaac Faber"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://towardsdatascience.com/@isaacfaber?source=placement_card_footer_grid---------0-41" data-action="show-user-card" data-action-source="placement_card_footer_grid---------0-41" data-action-value="81d6b9acba62" data-action-type="hover" data-user-id="81d6b9acba62" data-collection-slug="towards-data-science" dir="auto">Isaac Faber</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><span class="readingTime u-textColorNormal" title="10 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="a581dce1f5fc" data-is-label-padded="true" data-source="placement_card_footer_grid-----a581dce1f5fc----0-41----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/a581dce1f5fc" data-action-source="placement_card_footer_grid-----a581dce1f5fc----0-41----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="a581dce1f5fc">6.9K</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/a581dce1f5fc" data-action-source="placement_card_footer_grid-----a581dce1f5fc----0-41----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-width100pct u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackedPost" data-post-id="f0871519ca29" data-source="placement_card_footer_grid---------1-41" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://towardsdatascience.com/bringing-the-best-out-of-jupyter-notebooks-for-data-science-f0871519ca29?source=placement_card_footer_grid---------1-41" data-action-source="placement_card_footer_grid---------1-41"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-width100pct u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/0*kFimvWp5vJtxn4ws&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://towardsdatascience.com/bringing-the-best-out-of-jupyter-notebooks-for-data-science-f0871519ca29?source=placement_card_footer_grid---------1-41" data-action-source="placement_card_footer_grid---------1-41"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from Towards Data Science</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Bringing the best out of Jupyter Notebooks for Data Science</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@parulnith" data-action="show-user-card" data-action-value="7053de462a28" data-action-type="hover" data-user-id="7053de462a28" data-collection-slug="towards-data-science" dir="auto"><div class="u-relative u-inlineBlock u-flex0"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_-ooorT2_5GQSfQoVFxJHXw.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Parul Pandey"><div class="avatar-halo u-absolute u-textColorGreenNormal svgIcon" style="width: calc(100% + 10px); height: calc(100% + 10px); top:-5px; left:-5px"><svg viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M3.44615311,11.6601601 C6.57294867,5.47967718 12.9131553,1.5 19.9642857,1.5 C27.0154162,1.5 33.3556228,5.47967718 36.4824183,11.6601601 L37.3747245,11.2087295 C34.0793076,4.69494641 27.3961457,0.5 19.9642857,0.5 C12.5324257,0.5 5.84926381,4.69494641 2.55384689,11.2087295 L3.44615311,11.6601601 Z"></path><path d="M36.4824183,28.2564276 C33.3556228,34.4369105 27.0154162,38.4165876 19.9642857,38.4165876 C12.9131553,38.4165876 6.57294867,34.4369105 3.44615311,28.2564276 L2.55384689,28.7078582 C5.84926381,35.2216412 12.5324257,39.4165876 19.9642857,39.4165876 C27.3961457,39.4165876 34.0793076,35.2216412 37.3747245,28.7078582 L36.4824183,28.2564276 Z"></path></svg></div></div></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://towardsdatascience.com/@parulnith?source=placement_card_footer_grid---------1-41" data-action="show-user-card" data-action-source="placement_card_footer_grid---------1-41" data-action-value="7053de462a28" data-action-type="hover" data-user-id="7053de462a28" data-collection-slug="towards-data-science" dir="auto">Parul Pandey</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><span class="readingTime u-textColorNormal" title="9 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="f0871519ca29" data-is-label-padded="true" data-source="placement_card_footer_grid-----f0871519ca29----1-41----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/f0871519ca29" data-action-source="placement_card_footer_grid-----f0871519ca29----1-41----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="f0871519ca29">2.3K</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/f0871519ca29" data-action-source="placement_card_footer_grid-----f0871519ca29----1-41----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-width100pct u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackedPost" data-post-id="64b88099947" data-source="placement_card_footer_grid---------2-41" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://towardsdatascience.com/hacker-news-book-suggestions-64b88099947?source=placement_card_footer_grid---------2-41" data-action-source="placement_card_footer_grid---------2-41"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-width100pct u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/1*MMmlzztUmGro_ij6RBYMDg.jpeg&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://towardsdatascience.com/hacker-news-book-suggestions-64b88099947?source=placement_card_footer_grid---------2-41" data-action-source="placement_card_footer_grid---------2-41"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from Towards Data Science</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Hacker News book suggestions</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@mozzatoale" data-action="show-user-card" data-action-value="5057d3f6df60" data-action-type="hover" data-user-id="5057d3f6df60" data-collection-slug="towards-data-science" dir="auto"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_9N1V0y2z3RwvOD0637DVHw.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Alessandro Mozzato"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://towardsdatascience.com/@mozzatoale?source=placement_card_footer_grid---------2-41" data-action="show-user-card" data-action-source="placement_card_footer_grid---------2-41" data-action-value="5057d3f6df60" data-action-type="hover" data-user-id="5057d3f6df60" data-collection-slug="towards-data-science" dir="auto">Alessandro Mozzato</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><span class="readingTime u-textColorNormal" title="6 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="64b88099947" data-is-label-padded="true" data-source="placement_card_footer_grid-----64b88099947----2-41----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/64b88099947" data-action-source="placement_card_footer_grid-----64b88099947----2-41----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="64b88099947">695</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/64b88099947" data-action-source="placement_card_footer_grid-----64b88099947----2-41----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div></div></div></div></div><div class="u-padding0 u-clearfix u-backgroundGrayLightest u-print-hide supplementalPostContent js-responsesWrapper" data-action-scope="_actionscope_5"><div class="container u-maxWidth740"><div class="responsesStreamWrapper u-maxWidth640 js-responsesStreamWrapper"><div class="container responsesStream-title u-paddingTop15"><div class="row"><header class="heading"><div class="u-clearfix"><div class="heading-content u-floatLeft"><span class="heading-title heading-title--semibold">Responses</span></div></div></header></div></div><div class="responsesStream-editor cardChromeless u-marginBottom20 u-paddingLeft20 u-paddingRight20 js-responsesStreamEditor"><div class="u-paddingTop30 u-paddingBottom30 u-paddingLeft0 u-paddingRight0 u-borderBottomLightest js-responsesLoggedOutPrompt"><button class="button button--chromeless is-touchIconBlackPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--withIconAndLabel button--loggedOutPrompt" data-action="sign-up-prompt" data-redirect="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f#--respond" data-skip-onboarding="true" data-action-source="logged_out_response_prompt--------------------------respond_box"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"></path></svg></span><span class="button-label  js-buttonLabel">Write a response…</span></button></div></div><div class="responsesStream js-responsesStream"><div class="streamItem streamItem--conversation js-streamItem" data-action-scope="_actionscope_6"><div class="streamItemConversation"><div class="u-marginLeft20"><div class="streamItemConversation-divider"></div><header class="heading heading--light heading--simple"><div class="u-clearfix"><div class="heading-content u-floatLeft"><span class="heading-title">Conversation with <a class="link link--accent u-accentColor--textNormal u-baseColor--link" href="https://medium.com/@williamkoehrsen" data-action="show-user-card" data-action-value="e2f299e30cb9" data-action-type="hover" data-user-id="e2f299e30cb9" dir="auto">Will Koehrsen</a>.</span></div></div></header></div><div class="streamItemConversation-inner cardChromeless"><div class="streamItemConversationItem streamItemConversationItem--preview"><div class="postArticle js-postArticle js-trackedPost postArticle--short" data-post-id="48e6d5037db8" data-source="responses---------0---------------------" data-action-scope="_actionscope_7" data-scroll="native"><div class="u-clearfix u-marginBottom15 u-paddingTop5"><div class="postMetaInline u-floatLeft"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://medium.com/@spenceruresk" data-action="show-user-card" data-action-value="ad0678fe8445" data-action-type="hover" data-user-id="ad0678fe8445" dir="auto"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/0_liivsrtthLRpnTmg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Spencer Uresk"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--accent u-accentColor--textNormal u-accentColor--textDarken" href="https://medium.com/@spenceruresk?source=responses---------0---------------------" data-action="show-user-card" data-action-source="responses---------0---------------------" data-action-value="ad0678fe8445" data-action-type="hover" data-user-id="ad0678fe8445" dir="auto">Spencer Uresk</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://medium.com/@spenceruresk/at-what-point-does-hyperparameter-optimization-become-overfitting-48e6d5037db8?source=responses---------0---------------------" data-action="open-post" data-action-value="https://medium.com/@spenceruresk/at-what-point-does-hyperparameter-optimization-become-overfitting-48e6d5037db8?source=responses---------0---------------------" data-action-source="preview-listing"><time datetime="2018-06-24T17:34:45.756Z">Jun 24</time></a><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="1 min read"></span></div></div></div></div></div><div><a class="" href="https://medium.com/@spenceruresk/at-what-point-does-hyperparameter-optimization-become-overfitting-48e6d5037db8?source=responses---------0---------------------"><div class="postArticle-content js-postField"><section class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="4b3a" id="4b3a" class="graf graf--p graf--leading">At what point does hyperparameter optimization become overfitting? I see Kaggle kernels with 5+ decimal point values for all of the parameters and that just screams overfitting to me, especially when tied to a particular seed.</p><p name="37d9" id="37d9" class="graf graf--p graf-after--p graf--trailing">Have you come across anything that looks at good guidelines for avoiding overfitting in this way?</p></div></div></section></div></a></div><div class="u-clearfix u-paddingTop10"><div class="u-floatLeft"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="48e6d5037db8" data-is-flush-left="true" data-source="listing-----48e6d5037db8---------------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/48e6d5037db8" data-action-source="listing-----48e6d5037db8---------------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px is-flushLeft"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px is-flushLeft"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"></span></div></div><div class="buttonSet u-floatRight"><a class="button button--chromeless u-baseColor--buttonNormal" href="https://medium.com/@spenceruresk/at-what-point-does-hyperparameter-optimization-become-overfitting-48e6d5037db8?source=responses---------0---------------------#--responses" data-action-source="responses---------0---------------------">2 responses</a><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/48e6d5037db8" data-action-source="listing-----48e6d5037db8---------------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px is-flushRight"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px is-flushRight"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div><div class="streamItemConversationItem streamItemConversationItem--preview"><div class="postArticle js-postArticle js-trackedPost postArticle--short" data-post-id="3681614255d8" data-source="responses---------0---------------------" data-action-scope="_actionscope_8" data-scroll="native"><div class="u-clearfix u-marginBottom15 u-paddingTop5"><div class="postMetaInline u-floatLeft"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://medium.com/@williamkoehrsen" data-action="show-user-card" data-action-value="e2f299e30cb9" data-action-type="hover" data-user-id="e2f299e30cb9" dir="auto"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_SckxdIFfjlR-cWXkL5ya-g(2).jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Will Koehrsen"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--accent u-accentColor--textNormal u-accentColor--textDarken" href="https://medium.com/@williamkoehrsen?source=responses---------0---------------------" data-action="show-user-card" data-action-source="responses---------0---------------------" data-action-value="e2f299e30cb9" data-action-type="hover" data-user-id="e2f299e30cb9" dir="auto">Will Koehrsen</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><a class="link link--darken" href="https://medium.com/@williamkoehrsen/cross-validation-with-a-large-number-of-folds-10-is-what-i-most-commonly-see-recommended-to-3681614255d8?source=responses---------0---------------------" data-action="open-post" data-action-value="https://medium.com/@williamkoehrsen/cross-validation-with-a-large-number-of-folds-10-is-what-i-most-commonly-see-recommended-to-3681614255d8?source=responses---------0---------------------" data-action-source="preview-listing"><time datetime="2018-06-26T15:13:27.746Z">Jun 26</time></a><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="1 min read"></span></div></div></div></div></div><div><a class="" href="https://medium.com/@williamkoehrsen/cross-validation-with-a-large-number-of-folds-10-is-what-i-most-commonly-see-recommended-to-3681614255d8?source=responses---------0---------------------"><div class="postArticle-content js-postField"><section class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="ed9c" id="ed9c" class="graf graf--p graf--leading graf--trailing">Cross validation with a large number of folds (10+) is what I most commonly see recommended to reduce overfitting. To some extent, there will always be overfitting, even with cross-validation, because the hyperparameters are optimized to the training data which does not perfectly represent the testing data.</p></div></div></section></div></a></div><div class="u-clearfix u-paddingTop10"><div class="u-floatLeft"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="3681614255d8" data-is-flush-left="true" data-source="listing-----3681614255d8---------------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/3681614255d8" data-action-source="listing-----3681614255d8---------------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px is-flushLeft"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px is-flushLeft"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents" data-action="show-recommends" data-action-value="3681614255d8">1</button></span></div></div><div class="buttonSet u-floatRight"><a class="button button--chromeless u-baseColor--buttonNormal" href="https://medium.com/@williamkoehrsen/cross-validation-with-a-large-number-of-folds-10-is-what-i-most-commonly-see-recommended-to-3681614255d8?source=responses---------0---------------------#--responses" data-action-source="responses---------0---------------------">1 response</a><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/3681614255d8" data-action-source="listing-----3681614255d8---------------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px is-flushRight"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px is-flushRight"><svg class="svgIcon-use" width="25" height="25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div></div></div><div class="container js-showOtherResponses"><div class="row"><button class="button button--primary button--withChrome u-accentColor--buttonNormal responsesStream-showOtherResponses cardChromeless u-width100pct u-marginVertical20 u-heightAuto" data-action="show-other-responses">Show all responses</button></div></div><div class="responsesStream js-responsesStreamOther"></div></div></div></div><div class="supplementalPostContent js-heroPromo"></div></footer></article></main><aside class="u-marginAuto u-maxWidth1000 js-postLeftSidebar"><div class="u-foreground u-top0 u-fixed u-sm-hide js-postShareWidget u-transition--fadeIn300" data-scroll="fixed" style="transform: translateY(150px);"><ul><li class="u-marginVertical10"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="b8172278050f" data-is-icon-29px="true" data-has-recommend-list="true" data-source="post_share_widget-----b8172278050f---------------------clap_sidebar"><div class="u-relative u-foreground"><button class="button button--primary button--large button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--darker" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/b8172278050f" data-action-source="post_share_widget-----b8172278050f---------------------clap_sidebar" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><g fill-rule="evenodd"><path d="M13.739 1l.761 2.966L15.261 1z"></path><path d="M16.815 4.776l1.84-2.551-1.43-.471z"></path><path d="M10.378 2.224l1.84 2.551-.408-3.022z"></path><path d="M22.382 22.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L6.11 15.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L8.43 9.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L20.628 15c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM12.99 6.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><g fill-rule="evenodd"><path d="M13.738 1l.762 2.966L15.262 1z"></path><path d="M18.634 2.224l-1.432-.47-.408 3.022z"></path><path d="M11.79 1.754l-1.431.47 1.84 2.552z"></path><path d="M24.472 14.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M14.58 10.887c-.156-.83.096-1.569.692-2.142L12.78 6.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M17.812 10.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L9.2 7.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L7.046 9.54 5.802 8.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394l1.241 1.241 4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L4.89 11.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C21.74 20.8 22.271 18 20.62 14.982l-2.809-4.942z"></path></g></svg></span></span></button></div><span class="u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton" data-action="show-recommends" data-action-value="b8172278050f">2.2K</button></span></div></li><li class="u-marginVertical10 u-marginLeft3"><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/b8172278050f" data-action-source="post_share_widget-----b8172278050f---------------------bookmark_sidebar"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"></path></svg></span></span></button></li><li class="u-marginVertical10 u-marginLeft3"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" title="Share on Twitter" aria-label="Share on Twitter" data-action="share-on-twitter" data-action-source="post_share_widget"><span class="svgIcon svgIcon--twitterFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M22.053 7.54a4.474 4.474 0 0 0-3.31-1.455 4.526 4.526 0 0 0-4.526 4.524c0 .35.04.7.082 1.05a12.9 12.9 0 0 1-9.3-4.77c-.39.69-.61 1.46-.65 2.26.03 1.6.83 2.99 2.02 3.79-.72-.02-1.41-.22-2.02-.57-.01.02-.01.04 0 .08-.01 2.17 1.55 4 3.63 4.44-.39.08-.79.13-1.21.16-.28-.03-.57-.05-.81-.08.54 1.77 2.21 3.08 4.2 3.15a9.564 9.564 0 0 1-5.66 1.94c-.34-.03-.7-.06-1.05-.08 2 1.27 4.38 2.02 6.94 2.02 8.31 0 12.86-6.9 12.84-12.85.02-.24.01-.43 0-.65.89-.62 1.65-1.42 2.26-2.34-.82.38-1.69.62-2.59.72a4.37 4.37 0 0 0 1.94-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></span></button></li><li class="u-marginVertical10 u-marginLeft3"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" title="Share on Facebook" aria-label="Share on Facebook" data-action="share-on-facebook" data-action-source="post_share_widget"><span class="svgIcon svgIcon--facebookSquare svgIcon--29px"><svg class="svgIcon-use" width="29" height="29"><path d="M23.209 5H5.792A.792.792 0 0 0 5 5.791V23.21c0 .437.354.791.792.791h9.303v-7.125H12.72v-2.968h2.375v-2.375c0-2.455 1.553-3.662 3.741-3.662 1.049 0 1.95.078 2.213.112v2.565h-1.517c-1.192 0-1.469.567-1.469 1.397v1.963h2.969l-.594 2.968h-2.375L18.11 24h5.099a.791.791 0 0 0 .791-.791V5.79a.791.791 0 0 0-.791-.79"></path></svg></span></button></li></ul></div></aside><div class="u-fixed u-bottom0 u-width100pct u-backgroundWhite u-boxShadowTop u-borderBox u-paddingTop10 u-paddingBottom10 u-zIndexMetabar u-xs-paddingLeft10 u-xs-paddingRight10 js-stickyFooter"><div class="u-maxWidth700 u-marginAuto u-flexCenter"><div class="u-fontSize16 u-flex1 u-flexCenter"><div class="u-flex0 u-inlineBlock u-paddingRight20 u-xs-paddingRight10"><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://towardsdatascience.com/" title="Go to Towards Data Science" aria-label="Go to Towards Data Science" data-collection-slug="towards-data-science"><img src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/1_F0LADxTtsKOgmPa-_7iUEQ(1).jpeg" class="avatar-image avatar-image--smaller" alt="Towards Data Science"></a></div><div class="u-flex1 u-inlineBlock"><div class="u-xs-hide">Never miss a story from<strong> Towards Data Science</strong>, when you sign up for Medium. <a class="link u-baseColor--link link--accent u-accentColor--textNormal u-accentColor--textDarken" href="https://medium.com/@Medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg" data-action-source="sticky_footer">Learn more</a></div><div class="u-xs-show">Never miss a story from<strong> Towards Data Science</strong></div></div></div><div class="u-marginLeft50 u-xs-marginAuto"><button class="button button--primary button--dark is-active u-noUserSelect button--withChrome u-accentColor--buttonDark u-uiTextSemibold u-textUppercase u-fontSize12 button--followCollection js-followCollectionButton" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/towards-data-science" data-action-source="sticky_footer----7f60cf5620c9----------------------follow_metabar"><span class="button-label  button-defaultState js-buttonLabel">Get updates</span><span class="button-label button-activeState">Get updates</span></button></div></div></div><style class="js-collectionStyle">
.u-accentColor--borderLight {border-color: #668AAA !important;}
.u-accentColor--borderNormal {border-color: #668AAA !important;}
.u-accentColor--borderDark {border-color: #5A7690 !important;}
.u-accentColor--iconLight .svgIcon,.u-accentColor--iconLight.svgIcon {fill: #668AAA !important;}
.u-accentColor--iconNormal .svgIcon,.u-accentColor--iconNormal.svgIcon {fill: #668AAA !important;}
.u-accentColor--iconDark .svgIcon,.u-accentColor--iconDark.svgIcon {fill: #5A7690 !important;}
.u-accentColor--textNormal {color: #5A7690 !important;}
.u-accentColor--hoverTextNormal:hover {color: #5A7690 !important;}
.u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #546C83 !important;}
.u-accentColor--textDark {color: #546C83 !important;}
.u-accentColor--backgroundLight {background-color: #668AAA !important;}
.u-accentColor--backgroundNormal {background-color: #668AAA !important;}
.u-accentColor--backgroundDark {background-color: #5A7690 !important;}
.u-accentColor--buttonDark {border-color: #5A7690 !important; color: #546C83 !important;}
.u-accentColor--buttonDark:hover {border-color: #546C83 !important;}
.u-accentColor--buttonDark .icon:before,.u-accentColor--buttonDark .svgIcon{color: #5A7690 !important; fill: #5A7690 !important;}
.u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #668AAA !important; color: #5A7690 !important;}
.u-accentColor--buttonNormal:hover {border-color: #5A7690 !important;}
.u-accentColor--buttonNormal .icon:before,.u-accentColor--buttonNormal .svgIcon{color: #668AAA !important; fill: #668AAA !important;}
.u-accentColor--buttonNormal.button--filled .icon:before,.u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonDark.button--filled,.u-accentColor--buttonDark.button--withChrome.is-active,.u-accentColor--fillWhenActive.is-active {background-color: #5A7690 !important; border-color: #5A7690 !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #668AAA !important; border-color: #668AAA !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.postArticle.is-withAccentColors .markup--user,.postArticle.is-withAccentColors .markup--query {color: #5A7690 !important;}.u-tintBgColor {background-color: rgba(53, 88, 118, 1) !important;}.u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(53, 88, 118, 1) 0%, rgba(53, 88, 118, 0) 100%) !important;}.u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(53, 88, 118, 0) 0%, rgba(53, 88, 118, 1) 100%) !important;}
.u-tintSpectrum .u-baseColor--borderLight {border-color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--borderNormal {border-color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--borderDark {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--iconLight .svgIcon,.u-tintSpectrum .u-baseColor--iconLight.svgIcon {fill: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--iconNormal .svgIcon,.u-tintSpectrum .u-baseColor--iconNormal.svgIcon {fill: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--iconDark .svgIcon,.u-tintSpectrum .u-baseColor--iconDark.svgIcon {fill: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--textNormal {color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--textDark {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--textDarker {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--backgroundLight {background-color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--backgroundNormal {background-color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--backgroundDark {background-color: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--buttonLight {border-color: #9FB3C6 !important; color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--buttonLight:hover {border-color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--buttonLight .icon:before,.u-tintSpectrum .u-baseColor--buttonLight .svgIcon {color: #9FB3C6 !important; fill: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--buttonDark {border-color: #E9F1FA !important; color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--buttonDark:hover {border-color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--buttonDark .icon:before,.u-tintSpectrum .u-baseColor--buttonDark .svgIcon {color: #E9F1FA !important; fill: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--buttonNormal {border-color: #C5D2E1 !important; color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--buttonNormal:hover {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--buttonNormal .icon:before,.u-tintSpectrum .u-baseColor--buttonNormal .svgIcon {color: #C5D2E1 !important; fill: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--buttonDark.button--filled,.u-tintSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: #E9F1FA !important; border-color: #E9F1FA !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-baseColor--buttonNormal.button--filled,.u-tintSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: #C5D2E1 !important; border-color: #C5D2E1 !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-baseColor--link {color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--darken:hover,.u-tintSpectrum .u-baseColor--link.link--darken:focus,.u-tintSpectrum .u-baseColor--link.link--darken:active {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--dark {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:active {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--darker {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: #9FB3C6;}
.u-tintSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: #9FB3C6;}
.u-tintSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: #9FB3C6;}
.u-tintSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: #FBFFFF !important;}
.u-tintSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: #FBFFFF !important;}
.u-tintSpectrum  .ui-h1,.u-tintSpectrum  .ui-h2,.u-tintSpectrum  .ui-h3,.u-tintSpectrum  .ui-h4,.u-tintSpectrum  .ui-brand1,.u-tintSpectrum  .ui-brand2,.u-tintSpectrum  .ui-captionStrong {color: #FBFFFF !important; fill: #FBFFFF !important;}
.u-tintSpectrum  .ui-body,.u-tintSpectrum  .ui-caps {color: #FBFFFF !important; fill: #FBFFFF !important;}
.u-tintSpectrum  .ui-summary,.u-tintSpectrum  .ui-caption {color: #9FB3C6 !important; fill: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--borderLight {border-color: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--borderNormal {border-color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--borderDark {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--iconLight .svgIcon,.u-tintSpectrum .u-accentColor--iconLight.svgIcon {fill: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--iconNormal .svgIcon,.u-tintSpectrum .u-accentColor--iconNormal.svgIcon {fill: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--iconDark .svgIcon,.u-tintSpectrum .u-accentColor--iconDark.svgIcon {fill: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--textNormal {color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--hoverTextNormal:hover {color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--textDark {color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--backgroundLight {background-color: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--backgroundNormal {background-color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--backgroundDark {background-color: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--buttonDark {border-color: #E9F1FA !important; color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--buttonDark:hover {border-color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--buttonDark .icon:before,.u-tintSpectrum .u-accentColor--buttonDark .svgIcon{color: #E9F1FA !important; fill: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #C5D2E1 !important; color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--buttonNormal:hover {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--buttonNormal .icon:before,.u-tintSpectrum .u-accentColor--buttonNormal .svgIcon{color: #C5D2E1 !important; fill: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-tintSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-accentColor--buttonDark.button--filled,.u-tintSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-tintSpectrum .u-accentColor--fillWhenActive.is-active {background-color: #E9F1FA !important; border-color: #E9F1FA !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-tintSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #C5D2E1 !important; border-color: #C5D2E1 !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .postArticle.is-withAccentColors .markup--user,.u-tintSpectrum .postArticle.is-withAccentColors .markup--query {color: #C5D2E1 !important;}
.u-accentColor--highlightFaint {background-color: rgba(233, 242, 253, 1) !important;}
.u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(200, 228, 255, 1) !important;}
.postArticle.is-withAccentColors .markup--quote.is-other {background-color: rgba(233, 242, 253, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(233, 242, 253, 1), rgba(233, 242, 253, 1));}
.postArticle.is-withAccentColors .markup--quote.is-me {background-color: rgba(215, 235, 254, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(215, 235, 254, 1), rgba(215, 235, 254, 1));}
.postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: rgba(200, 228, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}
.postArticle.is-withAccentColors .markup--quote.is-selected {background-color: rgba(200, 228, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}
.postArticle.is-withAccentColors .markup--highlight {background-color: rgba(200, 228, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}.u-baseColor--iconNormal.avatar-halo {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}</style><style class="js-collectionStyleConstant">.u-imageBgColor {background-color: rgba(0, 0, 0, 0.24705882352941178);}
.u-imageSpectrum .u-baseColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconLight .svgIcon,.u-imageSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--iconNormal .svgIcon,.u-imageSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconDark .svgIcon,.u-imageSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDarker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important; color: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--buttonLight .icon:before,.u-imageSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark .icon:before,.u-imageSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal .icon:before,.u-imageSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonDark.button--filled,.u-imageSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal.button--filled,.u-imageSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--link {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-h1,.u-imageSpectrum  .ui-h2,.u-imageSpectrum  .ui-h3,.u-imageSpectrum  .ui-h4,.u-imageSpectrum  .ui-brand1,.u-imageSpectrum  .ui-brand2,.u-imageSpectrum  .ui-captionStrong {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-body,.u-imageSpectrum  .ui-caps {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-summary,.u-imageSpectrum  .ui-caption {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconLight .svgIcon,.u-imageSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--iconNormal .svgIcon,.u-imageSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconDark .svgIcon,.u-imageSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark .icon:before,.u-imageSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonDark.button--filled,.u-imageSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-imageSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-imageSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .postArticle.is-withAccentColors .markup--user,.u-imageSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--highlightFaint {background-color: rgba(255, 255, 255, 0.2) !important;}
.u-imageSpectrum .u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(255, 255, 255, 0.6) !important;}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: rgba(255, 255, 255, 0.2) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 0.2));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: rgba(255, 255, 255, 0.4) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.4), rgba(255, 255, 255, 0.4));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}.u-resetSpectrum .u-tintBgColor {background-color: rgba(255, 255, 255, 1) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(255, 255, 255, 1) 0%, rgba(255, 255, 255, 0) 100%) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(255, 255, 255, 0) 0%, rgba(255, 255, 255, 1) 100%) !important;}
.u-resetSpectrum .u-baseColor--borderLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderDark {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--iconLight .svgIcon,.u-resetSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconNormal .svgIcon,.u-resetSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconDark .svgIcon,.u-resetSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textNormal {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDarker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--backgroundLight {background-color: rgba(0, 0, 0, 0.09803921568627451) !important;}
.u-resetSpectrum .u-baseColor--backgroundNormal {background-color: rgba(0, 0, 0, 0.2) !important;}
.u-resetSpectrum .u-baseColor--backgroundDark {background-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight .icon:before,.u-resetSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark {border-color: rgba(0, 0, 0, 0.6) !important; color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--buttonDark .icon:before,.u-resetSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important; color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal .icon:before,.u-resetSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(0, 0, 0, 0.4980392156862745) !important; fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark.button--filled,.u-resetSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2980392156862745) !important; border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal.button--filled,.u-resetSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2) !important; border-color: rgba(0, 0, 0, 0.2) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--link {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--darken:active {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--link.link--darker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-h1,.u-resetSpectrum  .ui-h2,.u-resetSpectrum  .ui-h3,.u-resetSpectrum  .ui-h4,.u-resetSpectrum  .ui-brand1,.u-resetSpectrum  .ui-brand2,.u-resetSpectrum  .ui-captionStrong {color: rgba(0, 0, 0, 0.8) !important; fill: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum  .ui-body,.u-resetSpectrum  .ui-caps {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-summary,.u-resetSpectrum  .ui-caption {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-accentColor--borderLight {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderNormal {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderDark {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconLight .svgIcon,.u-resetSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--iconNormal .svgIcon,.u-resetSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconDark .svgIcon,.u-resetSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textDark {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundLight {background-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundNormal {background-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundDark {background-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark {border-color: rgba(0, 171, 107, 1) !important; color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark .icon:before,.u-resetSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(28, 153, 99, 1) !important; fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(2, 184, 117, 1) !important; color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(0, 171, 107, 1) !important; fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark.button--filled,.u-resetSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-resetSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(28, 153, 99, 1) !important; border-color: rgba(28, 153, 99, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-resetSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(0, 171, 107, 1) !important; border-color: rgba(0, 171, 107, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .postArticle.is-withAccentColors .markup--user,.u-resetSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(0, 171, 107, 1) !important;}</style><div class="highlightMenu" data-action-scope="_actionscope_3"><div class="highlightMenu-inner"><div class="buttonSet"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu u-accentColor--highlightStrong js-highlightMenuQuoteButton" data-action="sign-up-prompt" data-sign-in-action="quote" data-requires-token="true" data-skip-onboarding="true" data-redirect-type="quote" data-action-source="quote_menu--------------------------highlight_text"><span class="svgIcon svgIcon--highlighter svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M13.7 15.964l5.204-9.387-4.726-2.62-5.204 9.387 4.726 2.62zm-.493.885l-1.313 2.37-1.252.54-.702 1.263-3.796-.865 1.228-2.213-.202-1.35 1.314-2.37 4.722 2.616z" fill-rule="evenodd"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="sign-up-prompt" data-sign-in-action="quote-respond" data-redirect="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f" data-skip-onboarding="true" data-action-source="quote_menu--------------------------respond_text"><span class="svgIcon svgIcon--responseFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M19.074 21.117c-1.244 0-2.432-.37-3.532-1.096a7.792 7.792 0 0 1-.703-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.662 0 8.457 3.5 8.457 7.803 0 2.058-.85 3.984-2.403 5.448.023.17.06.35.118.55.192.69.537 1.38 1.026 2.04.15.21.172.48.058.7a.686.686 0 0 1-.613.38h-.03z" fill-rule="evenodd"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="twitter" data-action-source="quote_menu" data-skip-onboarding="true"><span class="svgIcon svgIcon--twitterFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><path d="M21.725 5.338c-.744.47-1.605.804-2.513 1.006a3.978 3.978 0 0 0-2.942-1.293c-2.22 0-4.02 1.81-4.02 4.02 0 .32.034.63.07.94-3.31-.18-6.27-1.78-8.255-4.23a4.544 4.544 0 0 0-.574 2.01c.04 1.43.74 2.66 1.8 3.38-.63-.01-1.25-.19-1.79-.5v.08c0 1.93 1.38 3.56 3.23 3.95-.34.07-.7.12-1.07.14-.25-.02-.5-.04-.72-.07.49 1.58 1.97 2.74 3.74 2.8a8.49 8.49 0 0 1-5.02 1.72c-.3-.03-.62-.04-.93-.07A11.447 11.447 0 0 0 8.88 21c7.386 0 11.43-6.13 11.414-11.414.015-.21.01-.38 0-.578a7.604 7.604 0 0 0 2.01-2.08 7.27 7.27 0 0 1-2.297.645 3.856 3.856 0 0 0 1.72-2.23"></path></svg></span></button><div class="buttonSet-separator"></div><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="sign-up-prompt" data-sign-in-action="highlight" data-redirect="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f" data-skip-onboarding="true" data-action-source="quote_menu--------------------------privatenote_text"><span class="svgIcon svgIcon--privatenoteFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25"><g fill-rule="evenodd"><path d="M17.662 4.552H7.346A4.36 4.36 0 0 0 3 8.898v5.685c0 2.168 1.614 3.962 3.697 4.28v2.77c0 .303.35.476.59.29l3.904-2.994h6.48c2.39 0 4.35-1.96 4.35-4.35V8.9c0-2.39-1.95-4.346-4.34-4.346zM16 14.31a.99.99 0 0 1-1.003.99h-4.994C9.45 15.3 9 14.85 9 14.31v-3.02a.99.99 0 0 1 1-.99v-.782a2.5 2.5 0 0 1 2.5-2.51c1.38 0 2.5 1.13 2.5 2.51v.782c.552.002 1 .452 1 .99v3.02z"></path><path d="M14 9.81c0-.832-.674-1.68-1.5-1.68-.833 0-1.5.84-1.5 1.68v.49h3v-.49z"></path></g></svg></span></button></div></div><div class="highlightMenu-arrowClip"><span class="highlightMenu-arrow"></span></div></div></div></div></div><div class="loadingBar"></div><script>// <![CDATA[
window["obvInit"] = function (opt_embedded) {window["obvInit"]["embedded"] = opt_embedded; window["obvInit"]["ready"] = true;}
// ]]></script><script>// <![CDATA[
var GLOBALS = {"audioUrl":"https://d1fcbxp97j4nb2.cloudfront.net","baseUrl":"https://towardsdatascience.com","buildLabel":"36146-3ba6baf","currentUser":{"userId":"lo_UCXUIzDzRwYd","isVerified":false,"subscriberEmail":"","hasPastMemberships":false,"isEnrolledInHightower":false,"isEligibleForHightower":false,"hightowerLastLockedAt":0,"isWriterProgramEnrolled":false,"isWriterProgramInvited":false,"isWriterProgramOptedOut":false,"writerProgramEnrolledAt":0,"friendLinkOnboarding":0,"hasAdditionalUnlocks":false},"currentUserHasUnverifiedEmail":false,"isAuthenticated":false,"isCurrentUserVerified":false,"language":"en-gb","miroUrl":"https://cdn-images-1.medium.com","moduleUrls":{"base":"https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.OPtJ9GJjFXqWanRfFSHx9Q.js","common-async":"https://cdn-static-1.medium.com/_/fp/gen-js/main-common-async.bundle.L89zOTTc91SRwNID1GXVQQ.js","hightower":"https://cdn-static-1.medium.com/_/fp/gen-js/main-hightower.bundle.sOll7BgmWpNorRP5_JnZFA.js","home-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-home-screens.bundle.xVioscTfDH8DHM2TFVxe_g.js","misc-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-misc-screens.bundle.7l70m47NuLK13TDnqdS9uA.js","notes":"https://cdn-static-1.medium.com/_/fp/gen-js/main-notes.bundle.DwUQqH03WhTYzOEe5sIZdQ.js","payments":"https://cdn-static-1.medium.com/_/fp/gen-js/main-payments.bundle.M6nTfm_fPYlSD_QNbHySMA.js","posters":"https://cdn-static-1.medium.com/_/fp/gen-js/main-posters.bundle.B1vBpn8ER0P6T8us_Mw60A.js","power-readers":"https://cdn-static-1.medium.com/_/fp/gen-js/main-power-readers.bundle.r3riuYqeUv058nWhwIf-Uw.js","pubs":"https://cdn-static-1.medium.com/_/fp/gen-js/main-pubs.bundle.lN6aNFGHy733emmT4aq7uA.js","stats":"https://cdn-static-1.medium.com/_/fp/gen-js/main-stats.bundle.5QeTLzlHFdrnkr7qSdik6g.js"},"previewConfig":{"weightThreshold":1,"weightImageParagraph":0.51,"weightIframeParagraph":0.8,"weightTextParagraph":0.08,"weightEmptyParagraph":0,"weightP":0.003,"weightH":0.005,"weightBq":0.003,"minPTextLength":60,"truncateBoundaryChars":20,"detectTitle":true,"detectTitleLevThreshold":0.15},"productName":"Medium","supportsEdit":true,"termsUrl":"//medium.com/policy/9db0094a1e0f","textshotHost":"textshot.medium.com","transactionId":"1545690147263:c2ef7c404901","useragent":{"browser":"chrome","family":"chrome","os":"","version":71,"supportsDesktopEdit":true,"supportsInteract":true,"supportsView":true,"isMobile":false,"isTablet":false,"isNative":false,"supportsFileAPI":true,"isTier1":true,"clientVersion":"","unknownParagraphsBad":false,"clientChannel":"","supportsRealScrollEvents":true,"supportsVhUnits":true,"ruinsViewportSections":false,"supportsHtml5Video":true,"supportsMagicUnderlines":true,"isWebView":false,"isFacebookWebView":false,"supportsProgressiveMedia":true,"supportsPromotedPosts":true,"isBot":false,"isNativeIphone":false,"supportsCssVariables":true,"supportsVideoSections":true,"emojiSupportLevel":1,"isSearchBot":false,"isSyndicationBot":false,"isNativeAndroid":false,"supportsScrollableMetabar":true},"variants":{"allow_access":true,"allow_signup":true,"allow_test_auth":"disallow","signin_services":"twitter,facebook,google,email,google-fastidv,google-one-tap","signup_services":"twitter,facebook,google,email,google-fastidv,google-one-tap","google_sign_in_android":true,"reengagement_notification_duration":3,"browsable_stream_config_bucket":"curated-topics","enable_dedicated_series_tab_api_ios":true,"enable_post_import":true,"available_monthly_plan":"60e220181034","available_annual_plan":"2c754bcc2995","disable_ios_resume_reading_toast":true,"is_not_medium_subscriber":true,"glyph_font_set":"m2","enable_branding":true,"enable_branding_fonts":true,"test_partner_program_payouts":true,"enable_friend_link_onboarding":true,"max_premium_content_per_user_under_metering":3,"enable_automated_mission_control_triggers":true,"enable_top_stories_for_you":true,"enable_ios_member_post_labeling":true,"enable_lite_profile":true,"app_download_email_template":"control","enable_topic_lifecycle_email":true,"enable_marketing_emails":true,"enable_truncated_rss_for_tags_and_topics":true,"enable_parsely":true,"enable_branch_io":true,"enable_branch_io_deeplinks":true,"enable_synchronous_parsely":true,"enable_ios_post_stats":true,"enable_lite_topics":true,"enable_lite_stories":true,"redis_read_write_splitting":true,"enable_tipalti_onboarding":true,"annual_renewal_reminder_email_variant":"fun","enable_annual_renewal_reminder_email":true,"enable_sift_integration":true,"enable_sift_science_webhook":true,"enable_new_collaborative_filtering_data":true,"android_rating_prompt_stories_read_threshold":2,"enable_gifting_flow":true,"enable_gift_button_metabar":true,"enable_unified_social_bar":true,"enable_new_author_lockup":true,"enable_live_post_post_scoring":true,"stripe_v3":true,"enable_topic_browse_mobile":true,"enable_google_one_tap":true,"enable_email_sign_in_captcha":true,"enable_ios_topics_on_search":true},"xsrfToken":"","iosAppId":"828256236","supportEmail":"yourfriends@medium.com","fp":{"/icons/monogram-mask.svg":"https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg","/icons/favicon-dev-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-dev-editor.YKKRxBO8EMvIqhyCwIiJeQ.ico","/icons/favicon-hatch-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-hatch-editor.BuEyHIqlyh2s_XEk4Rl32Q.ico","/icons/favicon-medium-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-medium-editor.PiakrZWB7Yb80quUVQWM6g.ico"},"authBaseUrl":"https://medium.com","imageUploadSizeMb":25,"isAuthDomainRequest":false,"domainCollectionSlug":"towards-data-science","algoliaApiEndpoint":"https://MQ57UUUQZ2-dsn.algolia.net","algoliaAppId":"MQ57UUUQZ2","algoliaSearchOnlyApiKey":"394474ced050e3911ae2249ecc774921","iosAppStoreUrl":"https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8","iosAppLinkBaseUrl":"medium:","algoliaIndexPrefix":"medium_","androidPlayStoreUrl":"https://play.google.com/store/apps/details?id=com.medium.reader","googleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","androidPackage":"com.medium.reader","androidPlayStoreMarketScheme":"market://details?id=com.medium.reader","googleAuthUri":"https://accounts.google.com/o/oauth2/auth","androidScheme":"medium","layoutData":{"useDynamicScripts":false,"googleAnalyticsTrackingCode":"UA-24232453-2","jsShivUrl":"https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js","useDynamicCss":false,"faviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico","faviconImageId":"1*8I-HPL0bfoIzGied-dzOvA.png","fontSets":[{"id":8,"url":"https://glyph.medium.com/css/e/sr/latin/e/ssr/latin/e/ssb/latin/m2.css"},{"id":11,"url":"https://glyph.medium.com/css/m2.css"},{"id":9,"url":"https://glyph.medium.com/css/mkt.css"},{"id":10,"url":"https://glyph.medium.com/css/elv8.css"}],"editorFaviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium-editor.3Y6xpZ-0FSdWDnPM3hSBIA.ico","glyphUrl":"https://glyph.medium.com"},"authBaseUrlRev":"moc.muidem//:sptth","isDnt":false,"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","archiveUploadSizeMb":100,"paymentData":{"currencies":{"1":{"label":"US Dollar","external":"usd"}},"countries":{"1":{"label":"United States of America","external":"US"}},"accountTypes":{"1":{"label":"Individual","external":"individual"},"2":{"label":"Company","external":"company"}}},"previewConfig2":{"weightThreshold":1,"weightImageParagraph":0.05,"raiseImage":true,"enforceHeaderHierarchy":true,"isImageInsetRight":true},"isAmp":false,"iosScheme":"medium","isSwBoot":false,"lightstep":{"accessToken":"ce5be895bef60919541332990ac9fef2","carrier":"{\"ot-tracer-spanid\":\"51684ba505c8a88b\",\"ot-tracer-traceid\":\"710c3fc90d772e16\",\"ot-tracer-sampled\":\"true\"}","host":"collector-medium.lightstep.com"},"facebook":{"key":"542599432471018","namespace":"medium-com","scope":{"default":["public_profile","email"],"connect":["public_profile","email"],"login":["public_profile","email"],"share":["public_profile","email"]}},"editorsPicksTopicId":"3985d2a191c5","popularOnMediumTopicId":"9d34e48ecf94","memberContentTopicId":"13d7efd82fb2","audioContentTopicId":"3792abbd134","brandedSequenceId":"7d337ddf1941","isDoNotAuth":false,"goldfinchUrl":"https://goldfinch.medium.com","buggle":{"url":"https://buggle.medium.com","videoUrl":"https://cdn-videos-1.medium.com","audioUrl":"https://cdn-audio-1.medium.com"},"referrerType":1,"isMeteredOut":false,"meterConfig":{"maxUnlockCount":3,"windowLength":"MONTHLY"},"partnerProgramEmail":"partnerprogram@medium.com","userResearchPrompts":[{"promptId":"lo_post_page_4","type":0,"url":"www.calendly.com"},{"promptId":"lo_home_page","type":1,"url":"www.calendly.com"},{"promptId":"lo_profile_page","type":2,"url":"www.calendly.com"}],"recaptchaKey":"6LdAokEUAAAAAC7seICd4vtC8chDb3jIXDQulyUJ","signinWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"countryCode":"GB","bypassMeter":false,"branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","paypal":{"clientMode":"production","oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com/redeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"}}}
// ]]></script><script charset="UTF-8" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/main-base.bundle.OPtJ9GJjFXqWanRfFSHx9Q.js" async=""></script><script>// <![CDATA[
window["obvInit"]({"value":{"id":"b8172278050f","versionId":"5ebb54bd5684","creatorId":"e2f299e30cb9","creator":{"userId":"e2f299e30cb9","name":"Will Koehrsen","username":"williamkoehrsen","createdAt":1420934438619,"imageId":"1*SckxdIFfjlR-cWXkL5ya-g.jpeg","backgroundImageId":"","bio":"Data Scientist at Cortex Intel, Data Science Communicator","twitterScreenName":"koehrsen_will","socialStats":{"userId":"e2f299e30cb9","usersFollowedCount":15,"usersFollowedByCount":17290,"type":"SocialStats"},"social":{"userId":"lo_UCXUIzDzRwYd","targetUserId":"e2f299e30cb9","type":"Social"},"facebookAccountId":"","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"type":"User"},"homeCollection":{"id":"7f60cf5620c9","name":"Towards Data Science","slug":"towards-data-science","tags":["DATA SCIENCE","MACHINE LEARNING","ARTIFICIAL INTELLIGENCE","BIG DATA","ANALYTICS"],"creatorId":"895063a310f4","description":"Sharing concepts, ideas, and codes.","shortDescription":"Sharing concepts, ideas, and codes.","image":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":154681,"activeAt":1545681430741},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"memberOfMembershipPlanId":"","isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"twitterUsername":"TDataScience","facebookPageName":"towardsdatascience","collectionMastheadId":"8b6aceffde6","domain":"towardsdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":3,"layout":2,"number":1,"postIds":["b541d7add21f"]}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["8665ed649687","969f8a935b18","b26a9f09fc70"],"sectionHeader":"Featured "}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":6,"postIds":[],"sectionHeader":"Latest"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["80d8992a0fc","ff8056029bc7"],"sectionHeader":"Our Letters"}},{"type":1,"postListMetadata":{"source":2,"layout":4,"number":6,"postIds":[],"sectionHeader":"Trending"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["3bf37f75a345","3920888f831c"],"sectionHeader":"Our Readers’ Guide"}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":9,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Editors' Picks"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["96667b06af5","766cdd74d13e"],"sectionHeader":"Contribute"}},{"type":1,"postListMetadata":{"source":4,"layout":5,"number":3,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Last Chance To Read"}}],"tintColor":"#FF355876","lightText":true,"favicon":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF668AAA","point":0},{"color":"#FF61809D","point":0.1},{"color":"#FF5A7690","point":0.2},{"color":"#FF546C83","point":0.3},{"color":"#FF4D6275","point":0.4},{"color":"#FF455768","point":0.5},{"color":"#FF3D4C5A","point":0.6},{"color":"#FF34414C","point":0.7},{"color":"#FF2B353E","point":0.8},{"color":"#FF21282F","point":0.9},{"color":"#FF161B1F","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF355876","point":0},{"color":"#FF4D6C88","point":0.1},{"color":"#FF637F99","point":0.2},{"color":"#FF7791A8","point":0.3},{"color":"#FF8CA2B7","point":0.4},{"color":"#FF9FB3C6","point":0.5},{"color":"#FFB2C3D4","point":0.6},{"color":"#FFC5D2E1","point":0.7},{"color":"#FFD7E2EE","point":0.8},{"color":"#FFE9F1FA","point":0.9},{"color":"#FFFBFFFF","point":1}],"backgroundColor":"#FF355876"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEDF4FC","point":0},{"color":"#FFE9F2FD","point":0.1},{"color":"#FFE6F1FD","point":0.2},{"color":"#FFE2EFFD","point":0.3},{"color":"#FFDFEEFD","point":0.4},{"color":"#FFDBECFE","point":0.5},{"color":"#FFD7EBFE","point":0.6},{"color":"#FFD4E9FE","point":0.7},{"color":"#FFD0E7FF","point":0.8},{"color":"#FFCCE6FF","point":0.9},{"color":"#FFC8E4FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":4,"title":"Data Science","url":"https://towardsdatascience.com/data-science/home","topicId":"cf416843aadc","source":"topicId"},{"type":4,"title":"Machine Learning","url":"https://towardsdatascience.com/machine-learning/home","topicId":"a5c9b2f1cb6b","source":"topicId"},{"type":4,"title":"Programming","url":"https://towardsdatascience.com/programming/home","topicId":"41533a1dc73c","source":"topicId"},{"type":4,"title":"Visualization","url":"https://towardsdatascience.com/data-visualization/home","topicId":"825e6cb8b9ce","source":"topicId"},{"type":4,"title":"AI","url":"https://towardsdatascience.com/artificial-intelligence/home","topicId":"7f029b17bf96","source":"topicId"},{"type":4,"title":"Picks","url":"https://towardsdatascience.com/editors-picks/home","topicId":"e81f4fc5ee6b","source":"topicId"},{"type":4,"title":"Contribute","url":"https://towardsdatascience.com/contribute/home","topicId":"6ae0c8697d8c","source":"topicId"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-19707169-24","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5},"paidForDomainAt":1509037374118,"type":"Collection"},"homeCollectionId":"7f60cf5620c9","title":"A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning","detectedLanguage":"en","latestVersion":"5ebb54bd5684","latestPublishedVersion":"5ebb54bd5684","hasUnpublishedEdits":false,"latestRev":3399,"createdAt":1529769313743,"updatedAt":1530564808248,"acceptedAt":0,"firstPublishedAt":1529846759216,"latestPublishedAt":1530564808248,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"The concepts behind efficient hyperparameter tuning using Bayesian optimization","bodyModel":{"paragraphs":[{"name":"d29d","type":4,"text":"","markups":[],"layout":3,"metadata":{"id":"1*CtJD4zJr6PNxbUZMwZxPKA.jpeg","originalWidth":1920,"originalHeight":1080}},{"name":"656a","type":3,"text":"A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning","markups":[]},{"name":"b640","type":13,"text":"The concepts behind efficient hyperparameter tuning using Bayesian optimization","markups":[]},{"name":"f9e6","type":1,"text":"Following are four common methods of hyperparameter optimization for machine learning in order of increasing efficiency:","markups":[]},{"name":"3b70","type":10,"text":"Manual","markups":[{"type":1,"start":0,"end":6}]},{"name":"3074","type":10,"text":"Grid search","markups":[{"type":1,"start":0,"end":11}]},{"name":"8b07","type":10,"text":"Random search","markups":[{"type":1,"start":0,"end":13}]},{"name":"f65e","type":10,"text":"Bayesian model-based optimization","markups":[{"type":1,"start":0,"end":33}]},{"name":"1a89","type":1,"text":"(There are also other methods such as evolutionary and gradient-based.)","markups":[{"type":3,"start":38,"end":51,"href":"https://en.wikipedia.org/wiki/Hyperparameter_optimization#Evolutionary_optimization","title":"","rel":"","anchorType":0},{"type":3,"start":55,"end":69,"href":"https://en.wikipedia.org/wiki/Hyperparameter_optimization#Gradient-based_optimization","title":"","rel":"","anchorType":0}]},{"name":"9f95","type":1,"text":"I was pretty proud that I’d recently moved up the ladder from manual to random search until I found this image deep in a paper by Bergstra et al.:","markups":[{"type":3,"start":121,"end":145,"href":"http://proceedings.mlr.press/v28/bergstra13.pdf","title":"","rel":"","anchorType":0}]},{"name":"1b8d","type":4,"text":"Validation Errors comparing random search and a model based approach on LFW (left) and PubFig83 (right)","markups":[],"layout":3,"metadata":{"id":"1*E0_THdPH2NfKB37JUQB8Eg.png","originalWidth":1007,"originalHeight":357}},{"name":"84c3","type":1,"text":"These figures compare validation error for hyperparameter optimization of an image classification neural network with random search in grey and Bayesian Optimization (using the Tree Parzen Estimator or TPE) in green. Lower is better: a smaller validation set error generally means better test set performance, and a smaller number of trials means less time invested. Clearly, there are significant advantages to Bayesian methods, and these graphs, along with other impressive results, convinced me it was time to take the next step and learn model-based hyperparameter optimization.","markups":[{"type":3,"start":459,"end":484,"href":"https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf","title":"","rel":"","anchorType":0}]},{"name":"9a9e","type":1,"text":"The one-sentence summary of Bayesian hyperparameter optimization is: build a probability model of the objective function and use it to select the most promising hyperparameters to evaluate in the true objective function.","markups":[{"type":3,"start":28,"end":64,"href":"https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf","title":"","rel":"","anchorType":0}]},{"name":"78f8","type":1,"text":"If you like to operate at a very high level, then this sentence may be all you need. However, if you want to understand the details, this article is my attempt to outline the concepts behind Bayesian optimization, in particular Sequential Model-Based Optimization (SMBO) with the Tree Parzen Estimator (TPE). With the mindset that you don’t know a concept until you can explain it to others, I went through several academic papers and will try to communicate the results in a (relatively) easy to understand format.","markups":[{"type":3,"start":407,"end":423,"href":"https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf","title":"","rel":"","anchorType":0},{"type":3,"start":424,"end":430,"href":"https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf","title":"","rel":"","anchorType":0}]},{"name":"3723","type":1,"text":"Although we can often implement machine learning methods without understanding how they work, I like to try and get an idea of what is going on so I can use the technique as effectively as possible. In later articles I’ll walk through using these methods in Python using libraries such as Hyperopt, so this article will lay the conceptual groundwork for implementations to come!","markups":[{"type":3,"start":289,"end":297,"href":"https://github.com/hyperopt/hyperopt","title":"","rel":"","anchorType":0}]},{"name":"aae1","type":1,"text":"Update: Here is a brief Jupyter Notebook showing the basics of using Bayesian Model-Based Optimization in the Hyperopt Python library.","markups":[{"type":3,"start":7,"end":40,"href":"https://github.com/WillKoehrsen/hyperparameter-optimization/blob/master/Introduction%20to%20Bayesian%20Optimization%20with%20Hyperopt.ipynb","title":"","rel":"","anchorType":0}]},{"name":"9416","type":3,"text":"Hyperparameter Optimization","markups":[]},{"name":"0b6f","type":1,"text":"The aim of hyperparameter optimization in machine learning is to find the hyperparameters of a given machine learning algorithm that return the best performance as measured on a validation set. (Hyperparameters, in contrast to model parameters, are set by the machine learning engineer before training. The number of trees in a random forest is a hyperparameter while the weights in a neural network are model parameters learned during training. I like to think of hyperparameters as the model settings to be tuned.)","markups":[]},{"name":"91fd","type":1,"text":"Hyperparameter optimization is represented in equation form as:","markups":[]},{"name":"f259","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*QR4_VOfAAWLVe2I0nqwtTg.png","originalWidth":390,"originalHeight":107}},{"name":"2c27","type":1,"text":"Here f(x) represents an objective score to minimize— such as RMSE or error rate— evaluated on the validation set; x* is the set of hyperparameters that yields the lowest value of the score, and x can take on any value in the domain X. In simple terms, we want to find the model hyperparameters that yield the best score on the validation set metric.","markups":[{"type":1,"start":263,"end":348}]},{"name":"bd05","type":1,"text":"The problem with hyperparameter optimization is that evaluating the objective function to find the score is extremely expensive. Each time we try different hyperparameters, we have to train a model on the training data, make predictions on the validation data, and then calculate the validation metric. With a large number of hyperparameters and complex models such as ensembles or deep neural networks that can take days to train, this process quickly becomes intractable to do by hand!","markups":[]},{"name":"f6db","type":1,"text":"Grid search and random search are slightly better than manual tuning because we set up a grid of model hyperparameters and run the train-predict -evaluate cycle automatically in a loop while we do more productive things (like feature engineering). However, even these methods are relatively inefficient because they do not choose the next hyperparameters to evaluate based on previous results. Grid and random search are completely uninformed by past evaluations, and as a result, often spend a significant amount of time evaluating “bad” hyperparameters.","markups":[{"type":3,"start":16,"end":49,"href":"http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf","title":"","rel":"","anchorType":0},{"type":3,"start":225,"end":245,"href":"https://www.featuretools.com/","title":"","rel":"","anchorType":0},{"type":1,"start":394,"end":464},{"type":2,"start":432,"end":443}]},{"name":"c268","type":1,"text":"For example, if we have the following graph with a lower score being better, where does it make sense to concentrate our search? If you said below 200 estimators, then you already have the idea of Bayesian optimization! We want to focus on the most promising hyperparameters, and if we have a record of evaluations, then it makes sense to use this information for our next choice.","markups":[]},{"name":"2a47","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*MiNXGrkk5BbjfkNAXZQSNA.png","originalWidth":560,"originalHeight":427}},{"name":"d0b1","type":1,"text":"Random and grid search pay no attention to past results at all and would keep searching across the entire range of the number of estimators even though it’s clear the optimal answer (probably) lies in a small region!","markups":[]},{"name":"9dd0","type":3,"text":"Bayesian Optimization","markups":[]},{"name":"d777","type":1,"text":"Bayesian approaches, in contrast to random or grid search, keep track of past evaluation results which they use to form a probabilistic model mapping hyperparameters to a probability of a score on the objective function:","markups":[{"type":3,"start":0,"end":19,"href":"https://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf","title":"","rel":"","anchorType":0}]},{"name":"c080","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*u00KlxHhd1fz6-Jaeou6PA.png","originalWidth":307,"originalHeight":58}},{"name":"1ab2","type":1,"text":"In the literature, this model is called a “surrogate” for the objective function and is represented as p(y | x). The surrogate is much easier to optimize than the objective function and Bayesian methods work by finding the next set of hyperparameters to evaluate on the actual objective function by selecting hyperparameters that perform best on the surrogate function. In other words:","markups":[{"type":3,"start":0,"end":17,"href":"https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf","title":"","rel":"","anchorType":0}]},{"name":"db12","type":10,"text":"Build a surrogate probability model of the objective function","markups":[{"type":1,"start":0,"end":61}]},{"name":"5cb5","type":10,"text":"Find the hyperparameters that perform best on the surrogate","markups":[{"type":1,"start":0,"end":59}]},{"name":"07a9","type":10,"text":"Apply these hyperparameters to the true objective function","markups":[{"type":1,"start":0,"end":58}]},{"name":"e350","type":10,"text":"Update the surrogate model incorporating the new results","markups":[{"type":1,"start":0,"end":56}]},{"name":"f18d","type":10,"text":"Repeat steps 2–4 until max iterations or time is reached","markups":[{"type":1,"start":0,"end":56}]},{"name":"b823","type":1,"text":"The aim of Bayesian reasoning is to become “less wrong” with more data which these approaches do by continually updating the surrogate probability model after each evaluation of the objective function.","markups":[{"type":3,"start":3,"end":70,"href":"https://towardsdatascience.com/bayes-rule-applied-75965e4482ff","title":"","rel":"","anchorType":0}]},{"name":"9fac","type":1,"text":"At a high-level, Bayesian optimization methods are efficient because they choose the next hyperparameters in an informed manner. The basic idea is: spend a little more time selecting the next hyperparameters in order to make fewer calls to the objective function. In practice, the time spent selecting the next hyperparameters is inconsequential compared to the time spent in the objective function. By evaluating hyperparameters that appear more promising from past results, Bayesian methods can find better model settings than random search in fewer iterations.","markups":[{"type":1,"start":127,"end":129},{"type":1,"start":148,"end":263},{"type":2,"start":112,"end":127}]},{"name":"f3ee","type":1,"text":"If there’s one thing to take away from this article it’s that Bayesian model-based methods can find better hyperparameters in less time because they reason about the best set of hyperparameters to evaluate based on past trials.","markups":[{"type":3,"start":62,"end":90,"href":"https://en.wikipedia.org/wiki/Hyperparameter_optimization#Bayesian_optimization","title":"","rel":"","anchorType":0}]},{"name":"6e58","type":1,"text":"As a good visual description of what is occurring in Bayesian Optimization take a look at the images below (source). The first shows an initial estimate of the surrogate model — in black with associated uncertainty in gray — after two evaluations. Clearly, the surrogate model is a poor approximation of the actual objective function in red:","markups":[{"type":3,"start":108,"end":114,"href":"https://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf","title":"","rel":"","anchorType":0}]},{"name":"4356","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*RQ-pAwQ88yC904QppChGPQ.png","originalWidth":1307,"originalHeight":637}},{"name":"7ef0","type":1,"text":"The next image shows the surrogate function after 8 evaluations. Now the surrogate almost exactly matches the true function. Therefore, if the algorithm selects the hyperparameters that maximize the surrogate, they will likely yield very good results on the true evaluation function.","markups":[]},{"name":"1bac","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*bSLAe1LCj3mMKfaZsQWCrw.png","originalWidth":1314,"originalHeight":631}},{"name":"0f1c","type":1,"text":"Bayesian methods have always made sense to me because they operate in much the same way we do: we form an initial view of the world (called a prior) and then we update our model based on new experiences (the updated model is called a posterior). Bayesian hyperparameter optimization takes that framework and applies it to finding the best value of model settings!","markups":[]},{"name":"4c1f","type":13,"text":"Sequential Model-Based Optimization","markups":[]},{"name":"b68b","type":1,"text":"Sequential model-based optimization (SMBO) methods (SMBO) are a formalization of Bayesian optimization. The sequential refers to running trials one after another, each time trying better hyperparameters by applying Bayesian reasoning and updating a probability model (surrogate).","markups":[{"type":3,"start":0,"end":57,"href":"https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf","title":"","rel":"","anchorType":0}]},{"name":"6cfd","type":1,"text":"There are five aspects of model-based hyperparameter optimization:","markups":[]},{"name":"e3d1","type":10,"text":"A domain of hyperparameters over which to search","markups":[{"type":1,"start":0,"end":48}]},{"name":"0434","type":10,"text":"An objective function which takes in hyperparameters and outputs a score that we want to minimize (or maximize)","markups":[{"type":1,"start":0,"end":111}]},{"name":"c1ce","type":10,"text":"The surrogate model of the objective function","markups":[{"type":1,"start":0,"end":45}]},{"name":"1c77","type":10,"text":"A criteria, called a selection function, for evaluating which hyperparameters to choose next from the surrogate model","markups":[{"type":1,"start":0,"end":117}]},{"name":"5352","type":10,"text":"A history consisting of (score, hyperparameter) pairs used by the algorithm to update the surrogate model","markups":[{"type":1,"start":0,"end":105}]},{"name":"417e","type":1,"text":"There are several variants of SMBO methods that differ in steps 3–4, namely, how they build a surrogate of the objective function and the criteria used to select the next hyperparameters. Several common choices for the surrogate model are Gaussian Processes, Random Forest Regressions, and Tree Parzen Estimators (TPE) while the most common choice for step 4 is Expected Improvement. In this post, we will focus on TPE and Expected Improvement.","markups":[{"type":3,"start":30,"end":54,"href":"https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf","title":"","rel":"","anchorType":0},{"type":3,"start":239,"end":257,"href":"https://en.wikipedia.org/wiki/Gaussian_process","title":"","rel":"","anchorType":0},{"type":3,"start":259,"end":284,"href":"http://aad.informatik.uni-freiburg.de/papers/13-GECCO-BBOB_SMAC.pdf","title":"","rel":"","anchorType":0}]},{"name":"fa1c","type":13,"text":"Domain","markups":[]},{"name":"d91e","type":1,"text":"In the case of random search and grid search, the domain of hyperparameters we search is a grid. An example for a random forest is shown below:","markups":[]},{"name":"7ae2","type":11,"text":"","markups":[],"layout":1,"iframe":{"mediaResourceId":"f6b581f613ecd6038d020b40a585335f"}},{"name":"1b0a","type":1,"text":"For a model-based approach, the domain consists of probability distributions. As with a grid, this lets us encode domain knowledge into the search process by placing greater probability in regions where we think the true best hyperparameters lie. If we wanted to express the above grid as a probability distribution, it may look something like this:","markups":[{"type":2,"start":51,"end":76}]},{"name":"0baa","type":4,"text":"","markups":[],"layout":6,"metadata":{"id":"1*luY6Ahh7uttR4quIcgOCBw.png","originalWidth":420,"originalHeight":279}},{"name":"c5f4","type":4,"text":"","markups":[],"layout":7,"metadata":{"id":"1*YfoPLKK8_WXIsRaQ7zcSjg.png","originalWidth":398,"originalHeight":279}},{"name":"b133","type":4,"text":"","markups":[],"layout":7,"metadata":{"id":"1*e6cIETdFd1rzD9ivofNJqw.png","originalWidth":395,"originalHeight":279}},{"name":"4528","type":1,"text":"Here we have a uniform, log-normal, and normal distribution. These are informed by prior practice/knowledge (for example the learning rate domain is usually a log-normal distribution over several orders of magnitude).","markups":[{"type":3,"start":125,"end":215,"href":"https://www.kdnuggets.com/2017/11/estimating-optimal-learning-rate-deep-neural-network.html","title":"","rel":"","anchorType":0}]},{"name":"56a8","type":13,"text":"Objective Function","markups":[]},{"name":"e473","type":1,"text":"The objective function takes in hyperparameters and outputs a single real-valued score that we want to minimize (or maximize). As an example, let’s consider the case of building a random forest for a regression problem. The hyperparameters we want to optimize are shown in the hyperparameter grid above and the score to minimize is the Root Mean Squared Error. Our objective function would then look like (in Python):","markups":[]},{"name":"a3b0","type":11,"text":"","markups":[],"layout":1,"iframe":{"mediaResourceId":"eb66de79843c965b04a82826e9c4416c"}},{"name":"8316","type":1,"text":"While the objective function looks simple, it is very expensive to compute! If the objective function could be quickly calculated, then we could try every single possible hyperparameter combination (like in grid search). If we are using a simple model, a small hyperparameter grid, and a small dataset, then this might be the best way to go. However, in cases where the objective function may take hours or even days to evaluate, we want to limit calls to it.","markups":[]},{"name":"efea","type":1,"text":"The entire concept of Bayesian model-based optimization is to reduce the number of times the objective function needs to be run by choosing only the most promising set of hyperparameters to evaluate based on previous calls to the evaluation function. The next set of hyperparameters are selected based on a model of the objective function called a surrogate.","markups":[]},{"name":"d36e","type":13,"text":"Surrogate Function (Probability Model)","markups":[]},{"name":"104e","type":1,"text":"The surrogate function, also called the response surface, is the probability representation of the objective function built using previous evaluations. This is called sometimes called a response surface because it is a high-dimensional mapping of hyperparameters to the probability of a score on the objective function. Below is a simple example with only two hyperparameters:","markups":[]},{"name":"9e7b","type":4,"text":"Response surface for AdaBoost algorithm (Source)","markups":[{"type":3,"start":41,"end":47,"href":"http://www.hylap.org/meta_data/adaboost/","title":"","rel":"","anchorType":0}],"layout":1,"metadata":{"id":"0*aBsprZzniYMB0KWc.png","originalWidth":480,"originalHeight":480}},{"name":"4bf1","type":1,"text":"There are several different forms of the surrogate function including Gaussian Processes and Random Forest regression. However, in this post we will focus on the Tree-structured Parzen Estimator as put forward by Bergstra et al in the paper “Algorithms for Hyper-Parameter Optimization”. These methods differ in how they construct the surrogate function which we’ll explain in just a bit. First we need to talk about the selection function.","markups":[{"type":3,"start":198,"end":227,"href":"https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf","title":"","rel":"","anchorType":0}]},{"name":"e1b4","type":13,"text":"Selection Function","markups":[]},{"name":"cbc5","type":1,"text":"The selection function is the criteria by which the next set of hyperparameters are chosen from the surrogate function. The most common choice of criteria is Expected Improvement:","markups":[]},{"name":"1df3","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*ebsqjhOTSGKBbIR_RLkjSQ.png","originalWidth":358,"originalHeight":83}},{"name":"6c7d","type":1,"text":"Here y* is a threshold value of the objective function, x is the proposed set of hyperparameters, y is the actual value of the objective function using hyperparameters x, and p(y | x) is the surrogate probability model expressing the probability of y given x. If that’s all a little much, in simpler terms, the aim is to maximize the Expected Improvement with respect to x. This means finding the best hyperparameters under the surrogate function p (y | x).","markups":[{"type":1,"start":307,"end":373}]},{"name":"044b","type":1,"text":"If p (y | x) is zero everywhere that y \x3c y*, then the hyperparameters x are not expected to yield any improvement. If the integral is positive, then it means that the hyperparameters x are expected to yield a better result than the threshold value.","markups":[]},{"name":"eba6","type":1,"text":"Tree-structured Parzen Estimator (TPE)","markups":[{"type":1,"start":0,"end":38}]},{"name":"118f","type":1,"text":"Now let’s get back to the surrogate function. The methods of SMBO differ in how they construct the surrogate model p(y | x). The Tree-structured Parzen Estimator builds a model by applying Bayes rule. Instead of directly representing p( y | x), it instead uses:","markups":[]},{"name":"68f2","type":4,"text":"Bayes Rule in Action!","markups":[],"layout":1,"metadata":{"id":"1*4D1QpDZzWpBOl7ANBhsSJA.png","originalWidth":256,"originalHeight":81}},{"name":"0f29","type":1,"text":"p (x | y), which is the probability of the hyperparameters given the score on the objective function, in turn is expressed:","markups":[]},{"name":"34a1","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*idWxsGylqq2ZaMGpHmbxDg.png","originalWidth":291,"originalHeight":80}},{"name":"a37c","type":1,"text":"where y \x3c y* represents a lower value of the objective function than the threshold. The explanation of this equation is that we make two different distributions for the hyperparameters: one where the value of the objective function is less than the threshold, l(x), and one where the value of the objective function is greater than the threshold, g(x).","markups":[{"type":2,"start":133,"end":184},{"type":2,"start":260,"end":265},{"type":2,"start":347,"end":351}]},{"name":"26ba","type":1,"text":"Let’s update our Random Forest graph to include a threshold:","markups":[]},{"name":"1c5e","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*H5pyf3G115WGJwPpg65yaQ.png","originalWidth":560,"originalHeight":427}},{"name":"ab03","type":1,"text":"Now we construct two probability distributions for the number of estimators, one using the estimators that yielded values under the threshold and one using the estimators that yielded values above the threshold.","markups":[]},{"name":"6541","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*6SH5O_ail54karro8j0NGg.png","originalWidth":580,"originalHeight":425}},{"name":"53c0","type":1,"text":"Intuitively, it seems that we want to draw values of x from l(x) and not from g(x) because this distribution is based only on values of x that yielded lower scores than the threshold. It turns out this is exactly what the math says as well! With Bayes Rule, and a few substitutions, the expected improvement equation (which we are trying to maximize) becomes:","markups":[{"type":2,"start":60,"end":65},{"type":2,"start":78,"end":83}]},{"name":"1d0d","type":4,"text":"","markups":[],"layout":1,"metadata":{"id":"1*ybiePL_8lKNouHlSb5OSgQ.png","originalWidth":623,"originalHeight":62}},{"name":"f1f6","type":1,"text":"The term on the far right is the most important part. What this says is that the Expected Improvement is proportional to the ratio l(x) / g(x) and therefore, to maximize the Expected Improvement, we should maximize this ratio. Our intuition was correct: we should draw values of the hyperparameters which are more likely under l(x) than under g(x)!","markups":[{"type":3,"start":81,"end":101,"href":"https://www.cse.wustl.edu/~garnett/cse515t/spring_2015/files/lecture_notes/12.pdf","title":"","rel":"","anchorType":0},{"type":2,"start":131,"end":143},{"type":2,"start":327,"end":332},{"type":2,"start":343,"end":347}]},{"name":"f5c5","type":1,"text":"The Tree-structured Parzen Estimator works by drawing sample hyperparameters from l(x), evaluating them in terms of l(x) / g(x), and returning the set that yields the highest value under l(x) / g(x) corresponding to the greatest expected improvement. These hyperparameters are then evaluated on the objective function. If the surrogate function is correct, then these hyperparameters should yield a better value when evaluated!","markups":[{"type":2,"start":82,"end":86},{"type":2,"start":116,"end":127},{"type":2,"start":187,"end":199},{"type":2,"start":249,"end":251}]},{"name":"4c81","type":1,"text":"The expected improvement criteria allows the model to balance exploration versus exploitation. l(x) is a distribution and not a single value which means that the hyperparameters drawn are likely close but not exactly at the maximum of the expected improvement. Moreover, because the surrogate is just an estimate of the objective function, the selected hyperparameters may not actually yield an improvement when evaluated and the surrogate model will have to be updated. This updating is done based on the current surrogate model and the history of objective function evaluations.","markups":[{"type":3,"start":62,"end":93,"href":"https://en.wikipedia.org/wiki/Multi-armed_bandit","title":"","rel":"","anchorType":0},{"type":2,"start":95,"end":99}]},{"name":"6b66","type":13,"text":"History","markups":[]},{"name":"e80c","type":1,"text":"Each time the algorithm proposes a new set of candidate hyperparameters, it evaluates them with the actual objective function and records the result in a pair (score, hyperparameters). These records form the history. The algorithm builds l(x) and g(x) using the history to come up with a probability model of the objective function that improves with each iteration.","markups":[{"type":1,"start":207,"end":215},{"type":2,"start":238,"end":243},{"type":2,"start":247,"end":252}]},{"name":"2f9f","type":1,"text":"This is Bayes’ Rule at work: we have an initial estimate for the surrogate of the objective function that we update as we gather more evidence. Eventually, with enough evaluations of the objective function, we hope that our model accurately reflects the objective function and the hyperparameters that yield the greatest Expected Improvement correspond to the hyperparameters that maximize the objective function.","markups":[{"type":3,"start":0,"end":27,"href":"https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7","title":"","rel":"","anchorType":0}]},{"name":"3261","type":3,"text":"Putting it All Together","markups":[{"type":1,"start":0,"end":23}]},{"name":"83dc","type":1,"text":"How do Sequential Model-Based Methods help us more efficiently search the hyperparameter space? Because the algorithm is proposing better candidate hyperparameters for evaluation, the score on the objective function improves much more rapidly than with random or grid search leading to fewer overall evaluations of the objective function.","markups":[]},{"name":"ff4b","type":1,"text":"Even though the algorithm spends more time selecting the next hyperparameters by maximizing the Expected Improvement, this is much cheaper in terms of computational cost than evaluating the objective function. In a paper about using SMBO with TPE, the authors reported that finding the next proposed set of candidate hyperparameters took several seconds, while evaluating the actual objective function took hours.","markups":[{"type":3,"start":210,"end":246,"href":"http://proceedings.mlr.press/v28/bergstra13.pdf","title":"","rel":"","anchorType":0}]},{"name":"86a5","type":1,"text":"If we are using better-informed methods to choose the next hyperparameters, that means we can spend less time evaluating poor hyperparameter choices. Furthermore, sequential model-based optimization using tree-structured Parzen estimators is able to find better hyperparameters than random search in the same number of trials. In other words, we get","markups":[]},{"name":"a9f8","type":9,"text":"Reduced running time of hyperparameter tuning","markups":[]},{"name":"1411","type":9,"text":"Better scores on the testing set","markups":[]},{"name":"946e","type":1,"text":"Hopefully, this has convinced you Bayesian model-based optimization is a technique worth trying!","markups":[]},{"name":"59f5","type":13,"text":"Implementation","markups":[]},{"name":"d075","type":1,"text":"Fortunately for us, there are now a number of libraries that can do SMBO in Python. Spearmint and MOE use a Gaussian Process for the surrogate, Hyperopt uses the Tree-structured Parzen Estimator, and SMAC uses a Random Forest regression. These libraries all use the Expected Improvement criterion to select the next hyperparameters from the surrogate model. In later articles we will take a look at using Hyperopt in Python and there are already several good articles and code examples for learning.","markups":[{"type":3,"start":84,"end":94,"href":"https://github.com/JasperSnoek/spearmint","title":"","rel":"","anchorType":0},{"type":3,"start":98,"end":101,"href":"https://github.com/Yelp/MOE","title":"","rel":"","anchorType":0},{"type":3,"start":144,"end":152,"href":"https://github.com/hyperopt/hyperopt","title":"","rel":"","anchorType":0},{"type":3,"start":200,"end":204,"href":"https://github.com/automl/SMAC3","title":"","rel":"","anchorType":0},{"type":3,"start":445,"end":454,"href":"http://fastml.com/optimizing-hyperparams-with-hyperopt/","title":"","rel":"","anchorType":0},{"type":3,"start":454,"end":458,"href":"https://github.com/jaberg/hyperopt/wiki/FMin","title":"","rel":"","anchorType":0},{"type":3,"start":472,"end":485,"href":"https://www.programcreek.com/python/example/98788/hyperopt.Trials","title":"","rel":"","anchorType":0}]},{"name":"c119","type":3,"text":"Conclusions","markups":[]},{"name":"48a7","type":1,"text":"Bayesian model-based optimization methods build a probability model of the objective function to propose smarter choices for the next set of hyperparameters to evaluate. SMBO is a formalization of Bayesian optimization which is more efficient at finding the best hyperparameters for a machine learning model than random or grid search.","markups":[{"type":1,"start":0,"end":335}]},{"name":"13b7","type":1,"text":"Sequential model-based optimization methods differ in they build the surrogate, but they all rely on information from previous trials to propose better hyperparameters for the next evaluation. The Tree Parzen Estimator is one algorithm that uses Bayesian reasoning to construct the surrogate model and can select the next hyperparameters using Expected Improvement.","markups":[]},{"name":"05b7","type":1,"text":"There are a number of libraries to implement SMBO in Python which we will explore in further articles. The concepts are a little tough at first, but understanding them will allow us to use the tools built on them more effectively. I’d like to mention I’m still trying to work my way through the details and if I’ve made a mistake, please let me know (civilly)!","markups":[]},{"name":"1eed","type":1,"text":"For more details, the following articles are extremely helpful:","markups":[]},{"name":"0fdc","type":10,"text":"Algorithms for Hyper-Parameter Optimization [Link]","markups":[{"type":3,"start":45,"end":49,"href":"https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf","title":"","rel":"","anchorType":0}]},{"name":"b3aa","type":10,"text":"Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures [Link]","markups":[{"type":3,"start":114,"end":118,"href":"http://proceedings.mlr.press/v28/bergstra13.pdf","title":"","rel":"","anchorType":0}]},{"name":"dcdf","type":10,"text":"Bayesian Optimization Primer [Link]","markups":[{"type":3,"start":30,"end":34,"href":"https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf","title":"","rel":"","anchorType":0}]},{"name":"4b47","type":10,"text":"Taking the Human Out of the Loop: A Review of Bayesian Optimization [Link]","markups":[{"type":3,"start":69,"end":73,"href":"https://www.cs.ox.ac.uk/people/nando.defreitas/publications/BayesOptLoop.pdf","title":"","rel":"","anchorType":0}]},{"name":"ce5f","type":1,"text":"As always, I welcome feedback and constructive criticism. I can be reached on Twitter @koehrsen_will","markups":[{"type":3,"start":86,"end":100,"href":"http://twitter.com/@koehrsen_will","title":"","rel":"","anchorType":0}]}],"sections":[{"name":"f037","startIndex":0},{"name":"1b52","startIndex":16},{"name":"31de","startIndex":43},{"name":"0fe7","startIndex":74},{"name":"3e39","startIndex":101}]},"postDisplay":{"coverless":true}},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"1*CtJD4zJr6PNxbUZMwZxPKA.jpeg","filter":"","backgroundSize":"","originalWidth":1920,"originalHeight":1080,"strategy":"resample","height":0,"width":0},"wordCount":3139,"imageCount":17,"readingTime":13.445283018867924,"subtitle":"The concepts behind efficient hyperparameter tuning using Bayesian optimization","publishedInCount":1,"usersBySocialRecommends":[],"noIndex":false,"recommends":367,"socialRecommends":[],"isBookmarked":false,"tags":[{"slug":"machine-learning","name":"Machine Learning","postCount":55348,"metadata":{"postCount":55348,"coverImage":{"id":"1*c1h9Q0lvSdhy5lrmMAq1Pw.png","originalWidth":1680,"originalHeight":960,"isFeatured":true}},"type":"Tag"},{"slug":"education","name":"Education","postCount":208671,"metadata":{"postCount":208671,"coverImage":{"id":"1*dVmAyTviHMkGJq46uvrLcg.jpeg"}},"type":"Tag"},{"slug":"bayesian-machine-learning","name":"Bayesian Machine Learning","postCount":97,"metadata":{"postCount":97,"coverImage":{"id":"1*Apj0joKBkK7VKHgOXIfMCg.png","originalWidth":1373,"originalHeight":747,"isFeatured":true}},"type":"Tag"},{"slug":"computer-science","name":"Computer Science","postCount":8998,"metadata":{"postCount":8998,"coverImage":{"id":"1*zLtGzztHd2BKpFfcqfVzMQ.png","originalWidth":760,"originalHeight":438,"isFeatured":true}},"type":"Tag"},{"slug":"towards-data-science","name":"Towards Data Science","postCount":1577,"metadata":{"postCount":1577,"coverImage":{"id":"0*kFimvWp5vJtxn4ws","originalWidth":5184,"originalHeight":3888,"isFeatured":true,"unsplashPhotoId":"o-ubWHV29Uk"}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":7,"links":{"entries":[{"url":"https://en.wikipedia.org/wiki/Hyperparameter_optimization#Evolutionary_optimization","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Hyperparameter_optimization#Gradient-based_optimization","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Hyperparameter_optimization#Bayesian_optimization","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Multi-armed_bandit","alts":[],"httpStatus":200},{"url":"https://en.wikipedia.org/wiki/Gaussian_process","alts":[],"httpStatus":200},{"url":"http://proceedings.mlr.press/v28/bergstra13.pdf","alts":[],"httpStatus":200},{"url":"https://www.featuretools.com/","alts":[],"httpStatus":200},{"url":"http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf","alts":[],"httpStatus":200},{"url":"https://github.com/jaberg/hyperopt/wiki/FMin","alts":[],"httpStatus":200},{"url":"https://github.com/hyperopt/hyperopt","alts":[],"httpStatus":200},{"url":"http://www.hylap.org/meta_data/adaboost/","alts":[],"httpStatus":200},{"url":"https://github.com/WillKoehrsen/hyperparameter-optimization/blob/master/Introduction%20to%20Bayesian%20Optimization%20with%20Hyperopt.ipynb","alts":[],"httpStatus":200},{"url":"https://github.com/automl/SMAC3","alts":[],"httpStatus":200},{"url":"https://www.kdnuggets.com/2017/11/estimating-optimal-learning-rate-deep-neural-network.html","alts":[],"httpStatus":200},{"url":"https://www.cse.wustl.edu/~garnett/cse515t/spring_2015/files/lecture_notes/12.pdf","alts":[],"httpStatus":200},{"url":"http://twitter.com/@koehrsen_will","alts":[{"type":2,"url":"twitter://user?screen_name=koehrsen_will"},{"type":3,"url":"twitter://user?screen_name=koehrsen_will"}],"httpStatus":200},{"url":"https://github.com/Yelp/MOE","alts":[],"httpStatus":200},{"url":"https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7","alts":[{"type":2,"url":"medium://p/e66e60791ea7"},{"type":3,"url":"medium://p/e66e60791ea7"}],"httpStatus":200},{"url":"https://github.com/JasperSnoek/spearmint","alts":[],"httpStatus":200},{"url":"https://towardsdatascience.com/bayes-rule-applied-75965e4482ff","alts":[{"type":2,"url":"medium://p/75965e4482ff"},{"type":3,"url":"medium://p/75965e4482ff"}],"httpStatus":200},{"url":"https://www.programcreek.com/python/example/98788/hyperopt.Trials","alts":[],"httpStatus":200},{"url":"https://sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf","alts":[],"httpStatus":200},{"url":"https://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf","alts":[],"httpStatus":200},{"url":"http://aad.informatik.uni-freiburg.de/papers/13-GECCO-BBOB_SMAC.pdf","alts":[],"httpStatus":200},{"url":"https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf","alts":[],"httpStatus":200},{"url":"https://www.cs.ox.ac.uk/people/nando.defreitas/publications/BayesOptLoop.pdf","alts":[],"httpStatus":200},{"url":"http://fastml.com/optimizing-hyperparams-with-hyperopt/","alts":[],"httpStatus":200}],"version":"0.3","generatedAt":1530564812531},"isLockedPreviewOnly":false,"takeoverId":"","metaDescription":"","totalClapCount":2297,"sectionCount":5,"readingList":0,"topics":[{"topicId":"1af65db9c2f8","slug":"artificial-intelligence","createdAt":1487916832419,"deletedAt":0,"image":{"id":"1*A28aHchbaA8zNVXraBq0Ug@2x.jpeg","originalWidth":4866,"originalHeight":3244},"name":"Artificial Intelligence","description":"Born to be bot.","briefCatalogId":"e811a1868896","relatedTopics":[],"visibility":1,"relatedTags":[],"type":"Topic"},{"topicId":"ae5d4995e225","slug":"data-science","createdAt":1493923906289,"deletedAt":0,"image":{"id":"1*NHWOEki_ncCX-xzbKtkEWw@2x.jpeg","originalWidth":5760,"originalHeight":3840},"name":"Data Science","description":"Query this.","briefCatalogId":"63c534ad8b15","relatedTopics":[],"visibility":1,"relatedTags":[],"type":"Topic"}]},"coverless":true,"slug":"a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":true,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f","previewContent":{"bodyModel":{"paragraphs":[{"name":"d29d","type":4,"text":"","markups":[],"layout":10,"metadata":{"id":"1*CtJD4zJr6PNxbUZMwZxPKA.jpeg","originalWidth":1920,"originalHeight":1080}},{"name":"656a","type":3,"text":"A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning","markups":[],"alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false,"subtitle":"The concepts behind efficient hyperparameter tuning using Bayesian optimization"},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f","approvedHomeCollectionId":"7f60cf5620c9","approvedHomeCollection":{"id":"7f60cf5620c9","name":"Towards Data Science","slug":"towards-data-science","tags":["DATA SCIENCE","MACHINE LEARNING","ARTIFICIAL INTELLIGENCE","BIG DATA","ANALYTICS"],"creatorId":"895063a310f4","description":"Sharing concepts, ideas, and codes.","shortDescription":"Sharing concepts, ideas, and codes.","image":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":154681,"activeAt":1545681430741},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"memberOfMembershipPlanId":"","isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"twitterUsername":"TDataScience","facebookPageName":"towardsdatascience","collectionMastheadId":"8b6aceffde6","domain":"towardsdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":3,"layout":2,"number":1,"postIds":["b541d7add21f"]}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["8665ed649687","969f8a935b18","b26a9f09fc70"],"sectionHeader":"Featured "}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":6,"postIds":[],"sectionHeader":"Latest"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["80d8992a0fc","ff8056029bc7"],"sectionHeader":"Our Letters"}},{"type":1,"postListMetadata":{"source":2,"layout":4,"number":6,"postIds":[],"sectionHeader":"Trending"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["3bf37f75a345","3920888f831c"],"sectionHeader":"Our Readers’ Guide"}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":9,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Editors' Picks"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["96667b06af5","766cdd74d13e"],"sectionHeader":"Contribute"}},{"type":1,"postListMetadata":{"source":4,"layout":5,"number":3,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Last Chance To Read"}}],"tintColor":"#FF355876","lightText":true,"favicon":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF668AAA","point":0},{"color":"#FF61809D","point":0.1},{"color":"#FF5A7690","point":0.2},{"color":"#FF546C83","point":0.3},{"color":"#FF4D6275","point":0.4},{"color":"#FF455768","point":0.5},{"color":"#FF3D4C5A","point":0.6},{"color":"#FF34414C","point":0.7},{"color":"#FF2B353E","point":0.8},{"color":"#FF21282F","point":0.9},{"color":"#FF161B1F","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF355876","point":0},{"color":"#FF4D6C88","point":0.1},{"color":"#FF637F99","point":0.2},{"color":"#FF7791A8","point":0.3},{"color":"#FF8CA2B7","point":0.4},{"color":"#FF9FB3C6","point":0.5},{"color":"#FFB2C3D4","point":0.6},{"color":"#FFC5D2E1","point":0.7},{"color":"#FFD7E2EE","point":0.8},{"color":"#FFE9F1FA","point":0.9},{"color":"#FFFBFFFF","point":1}],"backgroundColor":"#FF355876"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEDF4FC","point":0},{"color":"#FFE9F2FD","point":0.1},{"color":"#FFE6F1FD","point":0.2},{"color":"#FFE2EFFD","point":0.3},{"color":"#FFDFEEFD","point":0.4},{"color":"#FFDBECFE","point":0.5},{"color":"#FFD7EBFE","point":0.6},{"color":"#FFD4E9FE","point":0.7},{"color":"#FFD0E7FF","point":0.8},{"color":"#FFCCE6FF","point":0.9},{"color":"#FFC8E4FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":4,"title":"Data Science","url":"https://towardsdatascience.com/data-science/home","topicId":"cf416843aadc","source":"topicId"},{"type":4,"title":"Machine Learning","url":"https://towardsdatascience.com/machine-learning/home","topicId":"a5c9b2f1cb6b","source":"topicId"},{"type":4,"title":"Programming","url":"https://towardsdatascience.com/programming/home","topicId":"41533a1dc73c","source":"topicId"},{"type":4,"title":"Visualization","url":"https://towardsdatascience.com/data-visualization/home","topicId":"825e6cb8b9ce","source":"topicId"},{"type":4,"title":"AI","url":"https://towardsdatascience.com/artificial-intelligence/home","topicId":"7f029b17bf96","source":"topicId"},{"type":4,"title":"Picks","url":"https://towardsdatascience.com/editors-picks/home","topicId":"e81f4fc5ee6b","source":"topicId"},{"type":4,"title":"Contribute","url":"https://towardsdatascience.com/contribute/home","topicId":"6ae0c8697d8c","source":"topicId"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-19707169-24","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5},"paidForDomainAt":1509037374118,"type":"Collection"},"newsletterId":"","webCanonicalUrl":"https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f","mediumUrl":"https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"mongerRequestType":1,"layerCake":3,"socialTitle":"","socialDek":"","editorialPreviewTitle":"","editorialPreviewDek":"","curationEligibleAt":0,"primaryTopic":{"topicId":"ae5d4995e225","slug":"data-science","createdAt":1493923906289,"deletedAt":0,"image":{"id":"1*NHWOEki_ncCX-xzbKtkEWw@2x.jpeg","originalWidth":5760,"originalHeight":3840},"name":"Data Science","description":"Query this.","briefCatalogId":"63c534ad8b15","relatedTopics":[],"visibility":1,"relatedTags":[],"type":"Topic"},"type":"Post"},"mentionedUsers":[],"collaborators":[],"collectionUserRelations":[],"mode":null,"references":{"User":{"e2f299e30cb9":{"userId":"e2f299e30cb9","name":"Will Koehrsen","username":"williamkoehrsen","createdAt":1420934438619,"imageId":"1*SckxdIFfjlR-cWXkL5ya-g.jpeg","backgroundImageId":"","bio":"Data Scientist at Cortex Intel, Data Science Communicator","twitterScreenName":"koehrsen_will","socialStats":{"userId":"e2f299e30cb9","usersFollowedCount":15,"usersFollowedByCount":17290,"type":"SocialStats"},"social":{"userId":"lo_UCXUIzDzRwYd","targetUserId":"e2f299e30cb9","type":"Social"},"facebookAccountId":"","allowNotes":1,"mediumMemberAt":0,"isNsfw":false,"type":"User"}},"Collection":{"7f60cf5620c9":{"id":"7f60cf5620c9","name":"Towards Data Science","slug":"towards-data-science","tags":["DATA SCIENCE","MACHINE LEARNING","ARTIFICIAL INTELLIGENCE","BIG DATA","ANALYTICS"],"creatorId":"895063a310f4","description":"Sharing concepts, ideas, and codes.","shortDescription":"Sharing concepts, ideas, and codes.","image":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":154681,"activeAt":1545681430741},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false,"canLockOwnPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"memberOfMembershipPlanId":"","isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"twitterUsername":"TDataScience","facebookPageName":"towardsdatascience","collectionMastheadId":"8b6aceffde6","domain":"towardsdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":3,"layout":2,"number":1,"postIds":["b541d7add21f"]}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["8665ed649687","969f8a935b18","b26a9f09fc70"],"sectionHeader":"Featured "}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":6,"postIds":[],"sectionHeader":"Latest"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["80d8992a0fc","ff8056029bc7"],"sectionHeader":"Our Letters"}},{"type":1,"postListMetadata":{"source":2,"layout":4,"number":6,"postIds":[],"sectionHeader":"Trending"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["3bf37f75a345","3920888f831c"],"sectionHeader":"Our Readers’ Guide"}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":9,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Editors' Picks"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["96667b06af5","766cdd74d13e"],"sectionHeader":"Contribute"}},{"type":1,"postListMetadata":{"source":4,"layout":5,"number":3,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Last Chance To Read"}}],"tintColor":"#FF355876","lightText":true,"favicon":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF668AAA","point":0},{"color":"#FF61809D","point":0.1},{"color":"#FF5A7690","point":0.2},{"color":"#FF546C83","point":0.3},{"color":"#FF4D6275","point":0.4},{"color":"#FF455768","point":0.5},{"color":"#FF3D4C5A","point":0.6},{"color":"#FF34414C","point":0.7},{"color":"#FF2B353E","point":0.8},{"color":"#FF21282F","point":0.9},{"color":"#FF161B1F","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF355876","point":0},{"color":"#FF4D6C88","point":0.1},{"color":"#FF637F99","point":0.2},{"color":"#FF7791A8","point":0.3},{"color":"#FF8CA2B7","point":0.4},{"color":"#FF9FB3C6","point":0.5},{"color":"#FFB2C3D4","point":0.6},{"color":"#FFC5D2E1","point":0.7},{"color":"#FFD7E2EE","point":0.8},{"color":"#FFE9F1FA","point":0.9},{"color":"#FFFBFFFF","point":1}],"backgroundColor":"#FF355876"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEDF4FC","point":0},{"color":"#FFE9F2FD","point":0.1},{"color":"#FFE6F1FD","point":0.2},{"color":"#FFE2EFFD","point":0.3},{"color":"#FFDFEEFD","point":0.4},{"color":"#FFDBECFE","point":0.5},{"color":"#FFD7EBFE","point":0.6},{"color":"#FFD4E9FE","point":0.7},{"color":"#FFD0E7FF","point":0.8},{"color":"#FFCCE6FF","point":0.9},{"color":"#FFC8E4FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":4,"title":"Data Science","url":"https://towardsdatascience.com/data-science/home","topicId":"cf416843aadc","source":"topicId"},{"type":4,"title":"Machine Learning","url":"https://towardsdatascience.com/machine-learning/home","topicId":"a5c9b2f1cb6b","source":"topicId"},{"type":4,"title":"Programming","url":"https://towardsdatascience.com/programming/home","topicId":"41533a1dc73c","source":"topicId"},{"type":4,"title":"Visualization","url":"https://towardsdatascience.com/data-visualization/home","topicId":"825e6cb8b9ce","source":"topicId"},{"type":4,"title":"AI","url":"https://towardsdatascience.com/artificial-intelligence/home","topicId":"7f029b17bf96","source":"topicId"},{"type":4,"title":"Picks","url":"https://towardsdatascience.com/editors-picks/home","topicId":"e81f4fc5ee6b","source":"topicId"},{"type":4,"title":"Contribute","url":"https://towardsdatascience.com/contribute/home","topicId":"6ae0c8697d8c","source":"topicId"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-19707169-24","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5},"paidForDomainAt":1509037374118,"type":"Collection"}},"Social":{"e2f299e30cb9":{"userId":"lo_UCXUIzDzRwYd","targetUserId":"e2f299e30cb9","type":"Social"}},"SocialStats":{"e2f299e30cb9":{"userId":"e2f299e30cb9","usersFollowedCount":15,"usersFollowedByCount":17290,"type":"SocialStats"}}}})
// ]]></script><script id="parsely-cfg" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/p.js"></script><script type="text/javascript">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0); branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true}, function(err, data) {});</script><div class="surface-scrollOverlay"></div><script charset="UTF-8" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/main-common-async.bundle.L89zOTTc91SRwNID1GXVQQ.js"></script><script charset="UTF-8" src="./A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning_files/main-notes.bundle.DwUQqH03WhTYzOEe5sIZdQ.js"></script></body></html>